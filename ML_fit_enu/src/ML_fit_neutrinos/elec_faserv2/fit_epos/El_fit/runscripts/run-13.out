data before
341799.3120766666
13
data after
341799.3120766668
12
data,sig_tot
[4701.61488802 4794.88307404 4880.63321867 5022.96007778 5174.83210567
 5403.75702487 5484.3285967  5479.94484219 5685.56139019 5786.42431147
 5826.87977353 5997.03952734 6111.61127189 6120.00289282 6314.21918603
 6393.96946648 6488.95532514 6507.73738104 6584.88554107 6611.357542
 6727.02060846 6794.14329472 6832.33008524 6883.07023535 6889.97798261
 6892.59405288 6805.85090368 6823.13002919 6755.19764153 6760.12009368
 6724.68217864 6666.92058447 6621.02876806 6535.26290072 6361.28388017
 6274.38796295 6184.62147252 6083.25791251 5991.57607425 5831.76498353
 5653.0757575  5472.72752995 5256.93559567 5123.7074244  4954.91618422
 4767.66969394 4581.36906943 4384.37028734 4185.71288972 3987.35291917
 3772.17693952 3587.26519712 3410.17278209 3164.08533516 2970.74715477
 2808.67191304 2597.04856618 2414.5818751  2271.39044025 2134.37490034
 1969.09134909 1839.2544647  1690.72258547 1544.17473316 1392.50617358
 1256.91949139 1130.22399104 1023.21516166  912.20022068  790.05448549
  686.33353875  592.03819306  501.7262591   430.37252022  361.23753619
  302.43819468  248.36336026  193.91990061  153.43690413  116.10994345
   88.59143539   72.09509809   57.18948527   45.17032761   32.91651188
   23.26223598   37.57643872  779.76115757  819.33217103  853.43042069
  884.65267688  905.17657488  936.43865356  980.37304356 1027.01367349
 1051.38187235 1068.91684383 1110.52455855 1135.04707121 1192.86763646
 1191.06345875 1256.598203   1279.39982714 1292.55025959 1326.24235813
 1371.17906226 1383.39877461 1409.54882409 1440.35174162 1460.91223039
 1495.95384783 1499.85710062 1490.91907337 1518.89062738 1528.01817606
 1529.21479258 1539.75390574 1539.64933353 1533.97032378 1539.72900948
 1522.9274859  1516.18075167 1486.97149422 1468.42868357 1447.53539461
 1410.13886827 1401.85149154 1372.01665223 1337.1199038  1292.16995907
 1254.66423566 1225.9759354  1168.9167834  1138.15522019 1090.81463438
 1046.20720118  993.68326062  942.38183126  887.57792407  841.33509808
  786.62063997  740.35718354  685.13950905  638.57034564  599.23479559
  555.42460834  518.73884448  485.43492206  446.38917151  415.74835233
  378.13193845  345.07563002  310.85938377  281.28047609  252.35790433
  223.51141521  194.5085539   170.15787088  145.40697576  125.54449957
  107.71333166   95.97335247   83.7134781    70.73280236   59.5188732
   48.96558417   39.57817109   32.23744109   26.15284914   21.09817715
   28.97030946   23.63710235]
[4701.61488802 4794.88307404 4880.63321867 5022.96007778 5174.83210567
 5403.75702487 5484.3285967  5479.94484219 5685.56139019 5786.42431147
 5826.87977353 5997.03952734 6111.61127189 6120.00289282 6314.21918603
 6393.96946648 6488.95532514 6507.73738104 6584.88554107 6611.357542
 6727.02060846 6794.14329472 6832.33008524 6883.07023535 6889.97798261
 6892.59405288 6805.85090368 6823.13002919 6755.19764153 6760.12009368
 6724.68217864 6666.92058447 6621.02876806 6535.26290072 6361.28388017
 6274.38796295 6184.62147252 6083.25791251 5991.57607425 5831.76498353
 5653.0757575  5472.72752995 5256.93559567 5123.7074244  4954.91618422
 4767.66969394 4581.36906943 4384.37028734 4185.71288972 3987.35291917
 3772.17693952 3587.26519712 3410.17278209 3164.08533516 2970.74715477
 2808.67191304 2597.04856618 2414.5818751  2271.39044025 2134.37490034
 1969.09134909 1839.2544647  1690.72258547 1544.17473316 1392.50617358
 1256.91949139 1130.22399104 1023.21516166  912.20022068  790.05448549
  686.33353875  592.03819306  501.7262591   430.37252022  361.23753619
  302.43819468  248.36336026  193.91990061  153.43690413  116.10994345
   88.59143539   72.09509809   57.18948527   45.17032761   32.91651188
   23.26223598   37.57643872  779.76115757  819.33217103  853.43042069
  884.65267688  905.17657488  936.43865356  980.37304356 1027.01367349
 1051.38187235 1068.91684383 1110.52455855 1135.04707121 1192.86763646
 1191.06345875 1256.598203   1279.39982714 1292.55025959 1326.24235813
 1371.17906226 1383.39877461 1409.54882409 1440.35174162 1460.91223039
 1495.95384783 1499.85710062 1490.91907337 1518.89062738 1528.01817606
 1529.21479258 1539.75390574 1539.64933353 1533.97032378 1539.72900948
 1522.9274859  1516.18075167 1486.97149422 1468.42868357 1447.53539461
 1410.13886827 1401.85149154 1372.01665223 1337.1199038  1292.16995907
 1254.66423566 1225.9759354  1168.9167834  1138.15522019 1090.81463438
 1046.20720118  993.68326062  942.38183126  887.57792407  841.33509808
  786.62063997  740.35718354  685.13950905  638.57034564  599.23479559
  555.42460834  518.73884448  485.43492206  446.38917151  415.74835233
  378.13193845  345.07563002  310.85938377  281.28047609  252.35790433
  223.51141521  194.5085539   170.15787088  145.40697576  125.54449957
  107.71333166   95.97335247   83.7134781    70.73280236   59.5188732
   48.96558417   39.57817109   32.23744109   26.15284914   21.09817715
   28.97030946   23.63710235]
3.6586339162572385 12.73698104812132 38.02247903237222
val isze = 0
idinces = [111  19  68 105  66  67  90  47  10  49 148  98  59  99 168  20  81  39
 110   1  76 120 155 138 102 104  72 129 109 117 135 143 162 119  26  60
  55  24  58 116  21 112  61  56 114  87  91  43 145  82 134  35 132 144
   2  69  97  38  52  63 171 158 137  83  78  70 140  95  41  32 170  48
  25  53 101 121  51  14 164  29   3  23 127 160  37 161 159  45 106 130
  42  79 136 150 142  12 151  22  85   6 103 152 131 128  34 147  50 108
 163 124   4   5  44 166  96  84 149  28  75   7  46  17  11 153  71 118
  80 133 169  74  94 146  93  18  27  36  57  31  65  89  30  86  92 141
 126  13  77 154 165  33  62 122 107  88  54 139 100  16 115  40   0  73
   8 167 157 156 123 113  64  15 125   9]
training loss = 16.888996124267578 500
training loss = 16.322778701782227 1000
training loss = 15.760184288024902 1500
training loss = 15.247282028198242 2000
training loss = 14.780474662780762 2500
training loss = 14.34381103515625 3000
training loss = 13.93399429321289 3500
training loss = 13.592814445495605 4000
training loss = 11.260035514831543 4500
training loss = 2.8390488624572754 5000
training loss = 2.5502798557281494 5500
training loss = 2.4563798904418945 6000
training loss = 2.7012290954589844 6500
training loss = 2.403812885284424 7000
training loss = 2.3911032676696777 7500
training loss = 2.3749730587005615 8000
training loss = 2.3541061878204346 8500
training loss = 2.328993558883667 9000
training loss = 2.304908275604248 9500
training loss = 2.2855594158172607 10000
training loss = 2.5057313442230225 10500
training loss = 2.2608554363250732 11000
training loss = 2.2528796195983887 11500
training loss = 2.24611759185791 12000
training loss = 2.2415452003479004 12500
training loss = 2.238060712814331 13000
training loss = 2.235351800918579 13500
training loss = 2.2332587242126465 14000
training loss = 2.2316253185272217 14500
training loss = 2.2303457260131836 15000
training loss = 2.2293379306793213 15500
training loss = 2.2285208702087402 16000
training loss = 2.2278473377227783 16500
training loss = 2.227292776107788 17000
training loss = 2.22682785987854 17500
training loss = 2.295015811920166 18000
training loss = 2.2258434295654297 18500
training loss = 2.319424867630005 19000
training loss = 2.238635778427124 19500
training loss = 2.224233627319336 20000
training loss = 2.2229437828063965 20500
training loss = 2.221564769744873 21000
training loss = 2.2197420597076416 21500
training loss = 2.217592477798462 22000
training loss = 2.2155251502990723 22500
training loss = 2.2140579223632812 23000
training loss = 2.213409423828125 23500
training loss = 2.2155473232269287 24000
training loss = 2.2133407592773438 24500
reduced chi^2 level 2 = 2.216614007949829
Constrained alpha: 2.320633888244629
Constrained beta: 2.7556190490722656
Constrained gamma: 18.94222640991211
(1, 172)
(1, 0)
