data before
341799.3120766666
13
data after
341799.3120766668
12
data,sig_tot
[4701.61488802 4794.88307404 4880.63321867 5022.96007778 5174.83210567
 5403.75702487 5484.3285967  5479.94484219 5685.56139019 5786.42431147
 5826.87977353 5997.03952734 6111.61127189 6120.00289282 6314.21918603
 6393.96946648 6488.95532514 6507.73738104 6584.88554107 6611.357542
 6727.02060846 6794.14329472 6832.33008524 6883.07023535 6889.97798261
 6892.59405288 6805.85090368 6823.13002919 6755.19764153 6760.12009368
 6724.68217864 6666.92058447 6621.02876806 6535.26290072 6361.28388017
 6274.38796295 6184.62147252 6083.25791251 5991.57607425 5831.76498353
 5653.0757575  5472.72752995 5256.93559567 5123.7074244  4954.91618422
 4767.66969394 4581.36906943 4384.37028734 4185.71288972 3987.35291917
 3772.17693952 3587.26519712 3410.17278209 3164.08533516 2970.74715477
 2808.67191304 2597.04856618 2414.5818751  2271.39044025 2134.37490034
 1969.09134909 1839.2544647  1690.72258547 1544.17473316 1392.50617358
 1256.91949139 1130.22399104 1023.21516166  912.20022068  790.05448549
  686.33353875  592.03819306  501.7262591   430.37252022  361.23753619
  302.43819468  248.36336026  193.91990061  153.43690413  116.10994345
   88.59143539   72.09509809   57.18948527   45.17032761   32.91651188
   23.26223598   37.57643872  779.76115757  819.33217103  853.43042069
  884.65267688  905.17657488  936.43865356  980.37304356 1027.01367349
 1051.38187235 1068.91684383 1110.52455855 1135.04707121 1192.86763646
 1191.06345875 1256.598203   1279.39982714 1292.55025959 1326.24235813
 1371.17906226 1383.39877461 1409.54882409 1440.35174162 1460.91223039
 1495.95384783 1499.85710062 1490.91907337 1518.89062738 1528.01817606
 1529.21479258 1539.75390574 1539.64933353 1533.97032378 1539.72900948
 1522.9274859  1516.18075167 1486.97149422 1468.42868357 1447.53539461
 1410.13886827 1401.85149154 1372.01665223 1337.1199038  1292.16995907
 1254.66423566 1225.9759354  1168.9167834  1138.15522019 1090.81463438
 1046.20720118  993.68326062  942.38183126  887.57792407  841.33509808
  786.62063997  740.35718354  685.13950905  638.57034564  599.23479559
  555.42460834  518.73884448  485.43492206  446.38917151  415.74835233
  378.13193845  345.07563002  310.85938377  281.28047609  252.35790433
  223.51141521  194.5085539   170.15787088  145.40697576  125.54449957
  107.71333166   95.97335247   83.7134781    70.73280236   59.5188732
   48.96558417   39.57817109   32.23744109   26.15284914   21.09817715
   28.97030946   23.63710235]
[4701.61488802 4794.88307404 4880.63321867 5022.96007778 5174.83210567
 5403.75702487 5484.3285967  5479.94484219 5685.56139019 5786.42431147
 5826.87977353 5997.03952734 6111.61127189 6120.00289282 6314.21918603
 6393.96946648 6488.95532514 6507.73738104 6584.88554107 6611.357542
 6727.02060846 6794.14329472 6832.33008524 6883.07023535 6889.97798261
 6892.59405288 6805.85090368 6823.13002919 6755.19764153 6760.12009368
 6724.68217864 6666.92058447 6621.02876806 6535.26290072 6361.28388017
 6274.38796295 6184.62147252 6083.25791251 5991.57607425 5831.76498353
 5653.0757575  5472.72752995 5256.93559567 5123.7074244  4954.91618422
 4767.66969394 4581.36906943 4384.37028734 4185.71288972 3987.35291917
 3772.17693952 3587.26519712 3410.17278209 3164.08533516 2970.74715477
 2808.67191304 2597.04856618 2414.5818751  2271.39044025 2134.37490034
 1969.09134909 1839.2544647  1690.72258547 1544.17473316 1392.50617358
 1256.91949139 1130.22399104 1023.21516166  912.20022068  790.05448549
  686.33353875  592.03819306  501.7262591   430.37252022  361.23753619
  302.43819468  248.36336026  193.91990061  153.43690413  116.10994345
   88.59143539   72.09509809   57.18948527   45.17032761   32.91651188
   23.26223598   37.57643872  779.76115757  819.33217103  853.43042069
  884.65267688  905.17657488  936.43865356  980.37304356 1027.01367349
 1051.38187235 1068.91684383 1110.52455855 1135.04707121 1192.86763646
 1191.06345875 1256.598203   1279.39982714 1292.55025959 1326.24235813
 1371.17906226 1383.39877461 1409.54882409 1440.35174162 1460.91223039
 1495.95384783 1499.85710062 1490.91907337 1518.89062738 1528.01817606
 1529.21479258 1539.75390574 1539.64933353 1533.97032378 1539.72900948
 1522.9274859  1516.18075167 1486.97149422 1468.42868357 1447.53539461
 1410.13886827 1401.85149154 1372.01665223 1337.1199038  1292.16995907
 1254.66423566 1225.9759354  1168.9167834  1138.15522019 1090.81463438
 1046.20720118  993.68326062  942.38183126  887.57792407  841.33509808
  786.62063997  740.35718354  685.13950905  638.57034564  599.23479559
  555.42460834  518.73884448  485.43492206  446.38917151  415.74835233
  378.13193845  345.07563002  310.85938377  281.28047609  252.35790433
  223.51141521  194.5085539   170.15787088  145.40697576  125.54449957
  107.71333166   95.97335247   83.7134781    70.73280236   59.5188732
   48.96558417   39.57817109   32.23744109   26.15284914   21.09817715
   28.97030946   23.63710235]
2.3118441177144584 0.0075427563883789794 9.01115248331853
val isze = 0
idinces = [111  19  68 105  66  67  90  47  10  49 148  98  59  99 168  20  81  39
 110   1  76 120 155 138 102 104  72 129 109 117 135 143 162 119  26  60
  55  24  58 116  21 112  61  56 114  87  91  43 145  82 134  35 132 144
   2  69  97  38  52  63 171 158 137  83  78  70 140  95  41  32 170  48
  25  53 101 121  51  14 164  29   3  23 127 160  37 161 159  45 106 130
  42  79 136 150 142  12 151  22  85   6 103 152 131 128  34 147  50 108
 163 124   4   5  44 166  96  84 149  28  75   7  46  17  11 153  71 118
  80 133 169  74  94 146  93  18  27  36  57  31  65  89  30  86  92 141
 126  13  77 154 165  33  62 122 107  88  54 139 100  16 115  40   0  73
   8 167 157 156 123 113  64  15 125   9]
training loss = 24.471878051757812 500
training loss = 10.961695671081543 1000
training loss = 5.4699201583862305 1500
training loss = 3.384761333465576 2000
training loss = 2.757053852081299 2500
training loss = 2.567310333251953 3000
training loss = 2.4819161891937256 3500
training loss = 2.4257378578186035 4000
training loss = 2.3873212337493896 4500
training loss = 2.359271287918091 5000
training loss = 2.337782144546509 5500
training loss = 2.317643165588379 6000
training loss = 2.2842507362365723 6500
training loss = 2.2612063884735107 7000
training loss = 2.245558500289917 7500
training loss = 2.282681465148926 8000
training loss = 2.2354724407196045 8500
training loss = 2.458048105239868 9000
training loss = 2.3547990322113037 9500
training loss = 2.1586601734161377 10000
training loss = 2.140594720840454 10500
training loss = 2.124544143676758 11000
training loss = 2.109656810760498 11500
training loss = 2.092111587524414 12000
training loss = 2.0654120445251465 12500
training loss = 2.0444211959838867 13000
training loss = 2.0230002403259277 13500
training loss = 1.9988385438919067 14000
training loss = 1.9830180406570435 14500
training loss = 1.9679635763168335 15000
training loss = 1.9578720331192017 15500
training loss = 1.9506734609603882 16000
training loss = 1.945859670639038 16500
training loss = 1.9416290521621704 17000
training loss = 1.938665509223938 17500
training loss = 1.9440815448760986 18000
training loss = 1.9466584920883179 18500
training loss = 1.9333903789520264 19000
training loss = 1.9325848817825317 19500
training loss = 1.9315083026885986 20000
training loss = 1.9312732219696045 20500
reduced chi^2 level 2 = 1.9312885999679565
Constrained alpha: 2.455352783203125
Constrained beta: -0.8368651866912842
Constrained gamma: 14.871807098388672
(1, 172)
(1, 0)
