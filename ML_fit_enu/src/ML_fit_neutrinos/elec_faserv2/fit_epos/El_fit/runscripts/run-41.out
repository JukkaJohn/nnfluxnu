data before
341799.3120766666
13
data after
341799.3120766668
12
data,sig_tot
[4701.61488802 4794.88307404 4880.63321867 5022.96007778 5174.83210567
 5403.75702487 5484.3285967  5479.94484219 5685.56139019 5786.42431147
 5826.87977353 5997.03952734 6111.61127189 6120.00289282 6314.21918603
 6393.96946648 6488.95532514 6507.73738104 6584.88554107 6611.357542
 6727.02060846 6794.14329472 6832.33008524 6883.07023535 6889.97798261
 6892.59405288 6805.85090368 6823.13002919 6755.19764153 6760.12009368
 6724.68217864 6666.92058447 6621.02876806 6535.26290072 6361.28388017
 6274.38796295 6184.62147252 6083.25791251 5991.57607425 5831.76498353
 5653.0757575  5472.72752995 5256.93559567 5123.7074244  4954.91618422
 4767.66969394 4581.36906943 4384.37028734 4185.71288972 3987.35291917
 3772.17693952 3587.26519712 3410.17278209 3164.08533516 2970.74715477
 2808.67191304 2597.04856618 2414.5818751  2271.39044025 2134.37490034
 1969.09134909 1839.2544647  1690.72258547 1544.17473316 1392.50617358
 1256.91949139 1130.22399104 1023.21516166  912.20022068  790.05448549
  686.33353875  592.03819306  501.7262591   430.37252022  361.23753619
  302.43819468  248.36336026  193.91990061  153.43690413  116.10994345
   88.59143539   72.09509809   57.18948527   45.17032761   32.91651188
   23.26223598   37.57643872  779.76115757  819.33217103  853.43042069
  884.65267688  905.17657488  936.43865356  980.37304356 1027.01367349
 1051.38187235 1068.91684383 1110.52455855 1135.04707121 1192.86763646
 1191.06345875 1256.598203   1279.39982714 1292.55025959 1326.24235813
 1371.17906226 1383.39877461 1409.54882409 1440.35174162 1460.91223039
 1495.95384783 1499.85710062 1490.91907337 1518.89062738 1528.01817606
 1529.21479258 1539.75390574 1539.64933353 1533.97032378 1539.72900948
 1522.9274859  1516.18075167 1486.97149422 1468.42868357 1447.53539461
 1410.13886827 1401.85149154 1372.01665223 1337.1199038  1292.16995907
 1254.66423566 1225.9759354  1168.9167834  1138.15522019 1090.81463438
 1046.20720118  993.68326062  942.38183126  887.57792407  841.33509808
  786.62063997  740.35718354  685.13950905  638.57034564  599.23479559
  555.42460834  518.73884448  485.43492206  446.38917151  415.74835233
  378.13193845  345.07563002  310.85938377  281.28047609  252.35790433
  223.51141521  194.5085539   170.15787088  145.40697576  125.54449957
  107.71333166   95.97335247   83.7134781    70.73280236   59.5188732
   48.96558417   39.57817109   32.23744109   26.15284914   21.09817715
   28.97030946   23.63710235]
[4701.61488802 4794.88307404 4880.63321867 5022.96007778 5174.83210567
 5403.75702487 5484.3285967  5479.94484219 5685.56139019 5786.42431147
 5826.87977353 5997.03952734 6111.61127189 6120.00289282 6314.21918603
 6393.96946648 6488.95532514 6507.73738104 6584.88554107 6611.357542
 6727.02060846 6794.14329472 6832.33008524 6883.07023535 6889.97798261
 6892.59405288 6805.85090368 6823.13002919 6755.19764153 6760.12009368
 6724.68217864 6666.92058447 6621.02876806 6535.26290072 6361.28388017
 6274.38796295 6184.62147252 6083.25791251 5991.57607425 5831.76498353
 5653.0757575  5472.72752995 5256.93559567 5123.7074244  4954.91618422
 4767.66969394 4581.36906943 4384.37028734 4185.71288972 3987.35291917
 3772.17693952 3587.26519712 3410.17278209 3164.08533516 2970.74715477
 2808.67191304 2597.04856618 2414.5818751  2271.39044025 2134.37490034
 1969.09134909 1839.2544647  1690.72258547 1544.17473316 1392.50617358
 1256.91949139 1130.22399104 1023.21516166  912.20022068  790.05448549
  686.33353875  592.03819306  501.7262591   430.37252022  361.23753619
  302.43819468  248.36336026  193.91990061  153.43690413  116.10994345
   88.59143539   72.09509809   57.18948527   45.17032761   32.91651188
   23.26223598   37.57643872  779.76115757  819.33217103  853.43042069
  884.65267688  905.17657488  936.43865356  980.37304356 1027.01367349
 1051.38187235 1068.91684383 1110.52455855 1135.04707121 1192.86763646
 1191.06345875 1256.598203   1279.39982714 1292.55025959 1326.24235813
 1371.17906226 1383.39877461 1409.54882409 1440.35174162 1460.91223039
 1495.95384783 1499.85710062 1490.91907337 1518.89062738 1528.01817606
 1529.21479258 1539.75390574 1539.64933353 1533.97032378 1539.72900948
 1522.9274859  1516.18075167 1486.97149422 1468.42868357 1447.53539461
 1410.13886827 1401.85149154 1372.01665223 1337.1199038  1292.16995907
 1254.66423566 1225.9759354  1168.9167834  1138.15522019 1090.81463438
 1046.20720118  993.68326062  942.38183126  887.57792407  841.33509808
  786.62063997  740.35718354  685.13950905  638.57034564  599.23479559
  555.42460834  518.73884448  485.43492206  446.38917151  415.74835233
  378.13193845  345.07563002  310.85938377  281.28047609  252.35790433
  223.51141521  194.5085539   170.15787088  145.40697576  125.54449957
  107.71333166   95.97335247   83.7134781    70.73280236   59.5188732
   48.96558417   39.57817109   32.23744109   26.15284914   21.09817715
   28.97030946   23.63710235]
2.8093999918454453 10.85494072880774 30.210149685519138
val isze = 0
idinces = [111  19  68 105  66  67  90  47  10  49 148  98  59  99 168  20  81  39
 110   1  76 120 155 138 102 104  72 129 109 117 135 143 162 119  26  60
  55  24  58 116  21 112  61  56 114  87  91  43 145  82 134  35 132 144
   2  69  97  38  52  63 171 158 137  83  78  70 140  95  41  32 170  48
  25  53 101 121  51  14 164  29   3  23 127 160  37 161 159  45 106 130
  42  79 136 150 142  12 151  22  85   6 103 152 131 128  34 147  50 108
 163 124   4   5  44 166  96  84 149  28  75   7  46  17  11 153  71 118
  80 133 169  74  94 146  93  18  27  36  57  31  65  89  30  86  92 141
 126  13  77 154 165  33  62 122 107  88  54 139 100  16 115  40   0  73
   8 167 157 156 123 113  64  15 125   9]
training loss = 16.45496940612793 500
training loss = 16.034948348999023 1000
training loss = 15.748458862304688 1500
training loss = 15.425554275512695 2000
training loss = 15.062113761901855 2500
training loss = 14.683768272399902 3000
training loss = 14.261178970336914 3500
training loss = 2.983761787414551 4000
training loss = 2.8272130489349365 4500
training loss = 2.7270469665527344 5000
training loss = 2.621650218963623 5500
training loss = 2.5398142337799072 6000
training loss = 2.4952163696289062 6500
training loss = 2.470212459564209 7000
training loss = 2.474003791809082 7500
training loss = 2.440269947052002 8000
training loss = 2.430126905441284 8500
training loss = 2.421780586242676 9000
training loss = 2.414381742477417 9500
training loss = 2.4084315299987793 10000
training loss = 2.4034717082977295 10500
training loss = 2.3993873596191406 11000
training loss = 2.3961079120635986 11500
training loss = 2.525836706161499 12000
training loss = 2.3914527893066406 12500
training loss = 2.4382834434509277 13000
training loss = 2.3886711597442627 13500
training loss = 2.3877310752868652 14000
training loss = 2.387007474899292 14500
training loss = 2.3962459564208984 15000
training loss = 2.4518957138061523 15500
training loss = 2.38944149017334 16000
training loss = 2.3854000568389893 16500
training loss = 2.385042428970337 17000
training loss = 2.384857654571533 17500
training loss = 2.384702444076538 18000
training loss = 2.3845629692077637 18500
training loss = 2.384463310241699 19000
training loss = 2.384385824203491 19500
training loss = 2.3843255043029785 20000
training loss = 2.3842852115631104 20500
training loss = 2.384251832962036 21000
training loss = 2.384225606918335 21500
training loss = 2.3842146396636963 22000
training loss = 2.42611026763916 22500
reduced chi^2 level 2 = 2.384206533432007
Constrained alpha: 2.393913745880127
Constrained beta: 3.3451292514801025
Constrained gamma: 18.487951278686523
(1, 172)
(1, 0)
