data before
341734.2541035156
1
data after
341734.25410351576
5
data,sig_tot
[  201.69548438  2186.596       4741.1725      6806.304
  8415.142       9508.04       10293.872      10803.613
 11059.951      11244.94       11193.59       11106.22
 10915.06       10726.921      10398.065       9973.075
  9756.218       9357.004       9043.926       8619.225
  8341.463       8044.5045      7649.2345      7374.9705
  7005.915       6710.51        6467.6685      6197.199
  5833.9995      5635.4955      5329.8425      5074.8935
  4867.8355      4646.638       4429.836       4197.9315
  3945.307       3797.69        3620.51425     3463.5615
  3250.57        3098.35525     2943.80975     2799.6775
  2622.84425     2537.9205      2403.97025     2251.1695
  2126.283       2034.685875    1892.43925     1769.9575
  1668.828       1579.421875    1493.573625    1383.66375
  1293.98175     1226.202       1117.2615      1098.675625
  1027.611        972.4194375    871.5859375    789.113625
   748.63625      691.513        636.5791875    601.02075
   573.4458125    528.88525      479.33321875   415.75921875
   391.03565625   356.03071875   342.6669375    315.17771875
   272.60125      261.47465625   229.28953125   194.09942187
   181.34415625   163.05475      143.99895313   132.63742188
   117.78934375   102.31896875    91.19404687    75.37598438
    69.23158594    57.61450781    55.16546484    50.61793359
    44.56195313    35.34457422    34.54191016    28.24605664
    24.52100195    49.48642773    75.74399219   804.709125
  1763.31675     2504.259       3019.62675     3301.88875
  3459.874       3528.952       3494.8165      3421.0445
  3289.662       3155.9175      3023.6105      2839.2995
  2644.43775     2518.6575      2372.192       2216.62325
  2034.74975     1905.980375    1789.7635      1666.338
  1538.839375    1436.9455      1335.904375    1229.661625
  1144.643375    1058.539875     980.8401875    916.3586875
   842.4764375    779.5256875    715.1693125    681.832875
   620.082        586.245625     530.67075      490.98796875
   458.21353125   411.08625      390.2181875    352.11384375
   336.40353125   305.11284375   275.9941875    259.87478125
   224.37195313   215.4056875    199.71892188   185.792625
   172.99051563   152.30403125   140.4808125    126.99416406
   113.67026562   108.17124219    97.68226562    84.38951563
    82.0724375     76.03239063    65.07246484    56.03773828
    56.06823438    49.56273047    45.12332422    40.58268359
    40.0164375     31.57017187    31.18983984    29.12374805
    26.76495117    21.12873047    20.3756543     31.54842969
    27.04654102    22.25835938    22.87860156    21.58001465
    24.13499445]
[  201.69548438  2186.596       4741.1725      6806.304
  8415.142       9508.04       10293.872      10803.613
 11059.951      11244.94       11193.59       11106.22
 10915.06       10726.921      10398.065       9973.075
  9756.218       9357.004       9043.926       8619.225
  8341.463       8044.5045      7649.2345      7374.9705
  7005.915       6710.51        6467.6685      6197.199
  5833.9995      5635.4955      5329.8425      5074.8935
  4867.8355      4646.638       4429.836       4197.9315
  3945.307       3797.69        3620.51425     3463.5615
  3250.57        3098.35525     2943.80975     2799.6775
  2622.84425     2537.9205      2403.97025     2251.1695
  2126.283       2034.685875    1892.43925     1769.9575
  1668.828       1579.421875    1493.573625    1383.66375
  1293.98175     1226.202       1117.2615      1098.675625
  1027.611        972.4194375    871.5859375    789.113625
   748.63625      691.513        636.5791875    601.02075
   573.4458125    528.88525      479.33321875   415.75921875
   391.03565625   356.03071875   342.6669375    315.17771875
   272.60125      261.47465625   229.28953125   194.09942187
   181.34415625   163.05475      143.99895313   132.63742188
   117.78934375   102.31896875    91.19404687    75.37598438
    69.23158594    57.61450781    55.16546484    50.61793359
    44.56195313    35.34457422    34.54191016    28.24605664
    24.52100195    49.48642773    75.74399219   804.709125
  1763.31675     2504.259       3019.62675     3301.88875
  3459.874       3528.952       3494.8165      3421.0445
  3289.662       3155.9175      3023.6105      2839.2995
  2644.43775     2518.6575      2372.192       2216.62325
  2034.74975     1905.980375    1789.7635      1666.338
  1538.839375    1436.9455      1335.904375    1229.661625
  1144.643375    1058.539875     980.8401875    916.3586875
   842.4764375    779.5256875    715.1693125    681.832875
   620.082        586.245625     530.67075      490.98796875
   458.21353125   411.08625      390.2181875    352.11384375
   336.40353125   305.11284375   275.9941875    259.87478125
   224.37195313   215.4056875    199.71892188   185.792625
   172.99051563   152.30403125   140.4808125    126.99416406
   113.67026563   108.17124219    97.68226562    84.38951563
    82.0724375     76.03239062    65.07246484    56.03773828
    56.06823438    49.56273047    45.12332422    40.58268359
    40.0164375     31.57017187    31.18983984    29.12374805
    26.76495117    21.12873047    20.3756543     31.54842969
    27.04654102    22.25835938    22.87860156    21.58001465
    24.13499445]
1.2246641916147116 6.058855782105064 53.60631486781659
val isze = 0
idinces = [ 69 103  20 116  56  97 117  39 171  10  19  66  55  61 102  59  83  78
 110 163   1 160  47  49  67 136  68 133  60  76 170 169  70 167 124  26
  95  91  24 109 121  21 175  63  58  99 144  81  87  43 150 120 138  35
 173  82   2 114 153  38  52 142 176 146 148 101  80  72 145  98  41  32
 105  48  25  53  90 149  51  14 162  29   3  23 131 165  37 166 164  45
 111 134  42  79 143 155 119 147  12 127  22  85   6 106 112 135 132 104
  34 152 108  50 168 130 129   4   5  44 128  96  84 154  28  75   7  46
  17  11 158  71 118 137 174  74  94 151  93  18  27  36  57  31  65 140
  89  30  86  92 141 126  13  77 159 161  33  62 122 107  88  54 139 100
  16 115  40   0  73   8 172 157 156 123 113  64  15 125   9]
training loss = 5.016820430755615 500
training loss = 4.971290111541748 1000
training loss = 4.927463531494141 1500
training loss = 4.892822742462158 2000
training loss = 4.868085861206055 2500
training loss = 4.849664688110352 3000
training loss = 4.83113431930542 3500
training loss = 4.799152374267578 4000
training loss = 4.672611713409424 4500
training loss = 2.2948591709136963 5000
training loss = 2.2021586894989014 5500
training loss = 2.1921138763427734 6000
training loss = 2.192107915878296 6500
training loss = 2.192786931991577 7000
training loss = 2.1834957599639893 7500
training loss = 2.179203987121582 8000
training loss = 2.955939292907715 8500
training loss = 2.2638416290283203 9000
training loss = 2.198826789855957 9500
training loss = 2.1734797954559326 10000
training loss = 2.1674094200134277 10500
training loss = 2.1649887561798096 11000
training loss = 2.163074493408203 11500
training loss = 2.1613352298736572 12000
training loss = 2.159449577331543 12500
training loss = 2.1602039337158203 13000
training loss = 2.1631124019622803 13500
training loss = 2.1556828022003174 14000
training loss = 2.1532418727874756 14500
training loss = 2.15205454826355 15000
training loss = 2.1506283283233643 15500
training loss = 2.1506245136260986 16000
training loss = 2.148937225341797 16500
training loss = 2.147125482559204 17000
training loss = 2.147221326828003 17500
training loss = 2.151871919631958 18000
training loss = 2.428874969482422 18500
training loss = 2.1902782917022705 19000
training loss = 2.1458964347839355 19500
training loss = 2.1419637203216553 20000
training loss = 2.1406757831573486 20500
training loss = 2.1399495601654053 21000
training loss = 2.139375686645508 21500
training loss = 2.1384835243225098 22000
training loss = 2.1378376483917236 22500
training loss = 2.1372036933898926 23000
training loss = 2.1366069316864014 23500
training loss = 2.136023759841919 24000
training loss = 2.135456085205078 24500
training loss = 2.1349422931671143 25000
training loss = 2.134458303451538 25500
training loss = 2.1340441703796387 26000
training loss = 2.20330810546875 26500
training loss = 2.222647190093994 27000
training loss = 2.1330647468566895 27500
training loss = 2.1325178146362305 28000
training loss = 2.1332459449768066 28500
training loss = 2.158297538757324 29000
training loss = 2.1310696601867676 29500
training loss = 2.1307289600372314 30000
training loss = 2.1303834915161133 30500
training loss = 2.1300511360168457 31000
training loss = 2.1297473907470703 31500
training loss = 2.129455804824829 32000
training loss = 2.1291563510894775 32500
training loss = 2.128868341445923 33000
training loss = 2.128600835800171 33500
training loss = 2.1283321380615234 34000
training loss = 2.1280879974365234 34500
training loss = 2.1278717517852783 35000
reduced chi^2 level 2 = 2.127870798110962
Constrained alpha: 2.764716148376465
Constrained beta: 4.0199103355407715
Constrained gamma: 14.685524940490723
(1, 177)
(1, 0)
