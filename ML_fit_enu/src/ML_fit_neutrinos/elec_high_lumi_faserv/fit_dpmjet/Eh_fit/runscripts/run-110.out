data before
[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.25975585e-03
 1.60981333e-01 1.45545166e+00 3.92817414e+00 7.17308914e+00
 1.18524091e+01 1.94137868e+01 2.86083110e+01 4.41597759e+01
 6.75006960e+01 9.24903288e+01 1.35687255e+02 2.08212561e+02
 2.47062037e+02 2.67480431e+02 2.89665436e+02 3.05938016e+02
 3.20553177e+02 3.17271208e+02 2.97782269e+02 2.61509231e+02
 2.05189016e+02 1.42481462e+02 8.18361036e+01 3.54348463e+01
 1.02885776e+01 1.10422096e+00 8.31241424e-03 0.00000000e+00
 0.00000000e+00]
5
data after
[24.579365126930632, 48.022097700525315, 44.15977593075912, 67.50069598114008, 92.49032875292527, 135.68725477870575, 208.21256120950193, 247.06203661856463, 267.48043070779113, 289.6654361061704, 305.9380158451243, 320.55317660851114, 317.2712080242484, 297.7822687258487, 261.50923108372905, 205.1890162373903, 142.4814623014413, 81.83610357068221, 46.83595724050366]
6
data,sig_tot
[ 24.57936513  48.0220977   44.15977593  67.50069598  92.49032875
 135.68725478 208.21256121 247.06203662 267.48043071 289.66543611
 305.93801585 320.55317661 317.27120802 297.78226873 261.50923108
 205.18901624 142.4814623   81.83610357  46.83595724  31.11414486
  40.9871635   32.56712572  46.40459378  64.82622074  64.23155529
  70.79951201  75.11058559  73.28738232  69.24634614  60.21439216
  50.27746397  39.89762707  28.19732779  32.17742522]
[ 24.57936513  48.0220977   44.15977593  67.50069598  92.49032875
 135.68725478 208.21256121 247.06203662 267.48043071 289.66543611
 305.93801585 320.55317661 317.27120802 297.78226873 261.50923108
 205.18901624 142.4814623   81.83610357  46.83595724  31.11414486
  40.9871635   32.56712572  46.40459378  64.82622074  64.23155529
  70.79951201  75.11058559  73.28738232  69.24634614  60.21439216
  50.27746397  39.89762707  28.19732779  32.17742522]
3.9637846747821106 19.947678638698196 79.99320530528924
val isze = 0
idinces = [22 23  2  7  5  3 12 14 29 13  1 21 18 20  6 11 32 19 26  4 24 10 31 33
  8 30 16 25 28 27 17  0 15  9]
training loss = 82.45195770263672 500
training loss = 1.9355181455612183 1000
training loss = 1.8363258838653564 1500
training loss = 1.7989178895950317 2000
training loss = 1.781130075454712 2500
training loss = 1.771872639656067 3000
training loss = 1.7662028074264526 3500
training loss = 1.763083577156067 4000
training loss = 1.7620521783828735 4500
training loss = 1.7579431533813477 5000
reduced chi^2 level 2 = 1.7579289674758911
Constrained alpha: 2.3097891807556152
Constrained beta: 3.952812910079956
Constrained gamma: 5.670494556427002
(1, 34)
(1, 0)
