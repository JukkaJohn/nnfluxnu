data before
[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 1.49062519e+02 1.67988628e+02 1.84756801e+02 1.99295740e+02
 2.08864602e+02 2.10892075e+02 2.05316543e+02 1.91526206e+02
 1.70422482e+02 1.43531808e+02 1.12766530e+02 8.29920548e+01
 5.87078476e+01 3.59768908e+01 1.80225255e+01 6.48677791e+00
 1.53443149e+00 1.42783723e-01 0.00000000e+00 0.00000000e+00
 0.00000000e+00]
5
data after
[149.06251885022414, 167.98862759559862, 184.75680104024315, 199.29574034196307, 208.86460212845705, 210.89207494948326, 205.3165431855517, 191.52620601430385, 170.42248197293986, 143.53180819428323, 112.76653015785716, 82.992054832881, 58.70784764996863, 35.97689084691096, 26.18651865839047]
8
data,sig_tot
[149.06251885 167.9886276  184.75680104 199.29574034 208.86460213
 210.89207495 205.31654319 191.52620601 170.42248197 143.53180819
 112.76653016  82.99205483  58.70784765  35.97689085  26.18651866
  25.01956498  29.76566371  34.57853534  39.0537924   42.78745488
  45.03327904  45.07523072  43.28156672  39.17596164  33.34568609
  25.6385597   45.33953963]
[149.06251885 167.9886276  184.75680104 199.29574034 208.86460213
 210.89207495 205.31654319 191.52620601 170.42248197 143.53180819
 112.76653016  82.99205483  58.70784765  35.97689085  26.18651866
  25.01956498  29.76566371  34.57853534  39.0537924   42.78745488
  45.03327904  45.07523072  43.28156672  39.17596164  33.34568609
  25.6385597   45.33953963]
4.960050621454473 15.009142620331083 48.410610588560246
val isze = 0
idinces = [ 7  5 18 21 11  1  2 12 24 14 13 20  3 25  6 19 10 23 26  8 22 16 17  0
 15  4  9]
training loss = 63.302947998046875 500
training loss = 62.24324417114258 1000
training loss = 60.29888153076172 1500
training loss = 56.783538818359375 2000
training loss = 51.84885025024414 2500
training loss = 44.05131912231445 3000
training loss = 31.97751235961914 3500
training loss = 24.30778694152832 4000
training loss = 21.628568649291992 4500
training loss = 20.06754493713379 5000
(1, 27)
(1, 0)
