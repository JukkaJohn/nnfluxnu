data before
[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 5.57657739e-04
 1.71135155e-02 1.52347393e-01 4.11047088e-01 7.62033217e-01
 1.28459682e+00 2.04822352e+00 3.04780042e+00 4.78439220e+00
 7.34570329e+00 1.02073014e+01 1.49571227e+01 2.31990165e+01
 2.72081787e+01 2.91976000e+01 3.11090995e+01 3.24987602e+01
 3.29278008e+01 3.11299224e+01 2.71913177e+01 2.21718881e+01
 1.65541988e+01 1.15686996e+01 7.49874866e+00 4.79488960e+00
 3.30518493e+00 2.81167137e+00 3.25595671e-01 0.00000000e+00
 0.00000000e+00]
7
data after
[30.061116575363595, 38.15613917980373, 27.208178735984266, 29.197599971288444, 31.10909952982128, 32.498760232516524, 32.92780081108138, 31.129922380243542, 27.191317670272294, 22.171888085323573, 46.85898872553864]
12
data,sig_tot
[30.06111658 38.15613918 27.20817874 29.19759997 31.10909953 32.49876023
 32.92780081 31.12992238 27.19131767 22.17188809 46.85898873 24.49231035
 31.84445334]
[30.06111658 38.15613918 27.20817874 29.19759997 31.10909953 32.49876023
 32.92780081 31.12992238 27.19131767 22.17188809 46.85898873 24.49231035
 31.84445334]
4.532227455036492 19.32522900881575 30.01765333922075
val isze = 0
idinces = [ 3  7 11  6  8  2 12  5 10  1  0  4  9]
training loss = 27.686429977416992 500
training loss = 25.916622161865234 1000
training loss = 25.125131607055664 1500
training loss = 24.95212173461914 2000
training loss = 24.84531021118164 2500
training loss = 24.719051361083984 3000
training loss = 24.560155868530273 3500
training loss = 24.355924606323242 4000
training loss = 24.07916831970215 4500
training loss = 23.66407012939453 5000
(1, 13)
(1, 0)
