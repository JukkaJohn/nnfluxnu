data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
2.6797338833502433 18.427817827962052 0.9935501865630969
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 0.8692764639854431 500
reduced chi^2 level 2 = 0.8856294751167297
Constrained alpha: 2.079615354537964
Constrained beta: 6.9091997146606445
Constrained gamma: 2.379758596420288
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 7.71645975112915 500
training loss = 7.4364752769470215 1000
training loss = 7.275871276855469 1500
training loss = 7.094024658203125 2000
training loss = 6.862852096557617 2500
training loss = 6.570743560791016 3000
training loss = 6.193500995635986 3500
training loss = 5.675833225250244 4000
training loss = 4.9191694259643555 4500
training loss = 3.8464620113372803 5000
training loss = 2.668144464492798 5500
training loss = 1.8805811405181885 6000
reduced chi^2 level 2 = 1.8795517683029175
Constrained alpha: 3.85395884513855
Constrained beta: 7.207119464874268
Constrained gamma: 73.67393493652344
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 22.96857452392578 500
training loss = 14.659229278564453 1000
training loss = 7.328047275543213 1500
training loss = 7.249691009521484 2000
training loss = 7.156783103942871 2500
training loss = 7.0341973304748535 3000
training loss = 6.862555503845215 3500
training loss = 6.596721649169922 4000
training loss = 6.126327991485596 4500
training loss = 5.188183784484863 5000
training loss = 3.4714016914367676 5500
training loss = 1.9202091693878174 6000
reduced chi^2 level 2 = 1.918399453163147
Constrained alpha: 3.858886957168579
Constrained beta: 6.8666300773620605
Constrained gamma: 72.03701782226562
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 7.674806118011475 500
training loss = 7.45582914352417 1000
training loss = 7.388727188110352 1500
training loss = 7.3271002769470215 2000
training loss = 7.250013828277588 2500
training loss = 7.152449131011963 3000
training loss = 7.025534629821777 3500
training loss = 6.850390911102295 4000
training loss = 6.5845746994018555 4500
training loss = 6.122208118438721 5000
training loss = 5.172021865844727 5500
training loss = 3.334543466567993 6000
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 25.199005126953125 500
training loss = 24.002124786376953 1000
training loss = 22.388999938964844 1500
training loss = 10.232699394226074 2000
training loss = 6.012582778930664 2500
training loss = 5.623867988586426 3000
training loss = 4.8008036613464355 3500
training loss = 3.4498953819274902 4000
training loss = 2.3531501293182373 4500
training loss = 1.8534938097000122 5000
training loss = 1.6413261890411377 5500
training loss = 1.5275770425796509 6000
reduced chi^2 level 2 = 1.5273993015289307
Constrained alpha: 3.6357789039611816
Constrained beta: 7.475461959838867
Constrained gamma: 73.09846496582031
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 7.520846843719482 500
training loss = 7.343569755554199 1000
training loss = 7.257119655609131 1500
training loss = 7.159012317657471 2000
training loss = 7.0408034324646 2500
training loss = 6.891294479370117 3000
training loss = 6.684994220733643 3500
training loss = 6.361994743347168 4000
training loss = 5.765549182891846 4500
training loss = 4.520869255065918 5000
training loss = 2.5954482555389404 5500
training loss = 1.6357144117355347 6000
reduced chi^2 level 2 = 1.634959101676941
Constrained alpha: 3.860487699508667
Constrained beta: 6.716124534606934
Constrained gamma: 71.23751831054688
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 8.3597993850708 500
training loss = 7.520900726318359 1000
training loss = 7.480555534362793 1500
training loss = 7.450988292694092 2000
training loss = 7.412162780761719 2500
training loss = 7.3615851402282715 3000
training loss = 7.295941352844238 3500
training loss = 7.2100510597229 4000
training loss = 7.095097541809082 4500
training loss = 6.934232234954834 5000
training loss = 6.689888954162598 5500
training loss = 6.255152702331543 6000
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 8.46540355682373 500
training loss = 7.625853061676025 1000
training loss = 7.465809345245361 1500
training loss = 7.432616710662842 2000
training loss = 7.407387733459473 2500
training loss = 7.377039432525635 3000
training loss = 7.339840888977051 3500
training loss = 7.293664932250977 4000
training loss = 7.234450817108154 4500
training loss = 7.1539716720581055 5000
training loss = 7.034784317016602 5500
training loss = 6.835786819458008 6000
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 9.08795166015625 500
training loss = 7.287712097167969 1000
training loss = 7.136900424957275 1500
training loss = 7.025862216949463 2000
training loss = 6.878674507141113 2500
training loss = 6.670944690704346 3000
training loss = 6.347906589508057 3500
training loss = 5.786665916442871 4000
training loss = 4.75649881362915 4500
training loss = 3.1881515979766846 5000
training loss = 1.9336004257202148 5500
training loss = 1.5039458274841309 6000
reduced chi^2 level 2 = 1.5035701990127563
Constrained alpha: 3.8596031665802
Constrained beta: 7.100894927978516
Constrained gamma: 73.03839874267578
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 9.046699523925781 500
training loss = 7.431684970855713 1000
training loss = 7.219578266143799 1500
training loss = 7.13669490814209 2000
training loss = 7.040856838226318 2500
training loss = 6.916398525238037 3000
training loss = 6.745064735412598 3500
training loss = 6.485382556915283 4000
training loss = 6.040822505950928 4500
training loss = 5.2020745277404785 5000
training loss = 3.7261664867401123 5500
training loss = 2.1703667640686035 6000
reduced chi^2 level 2 = 2.1681418418884277
Constrained alpha: 3.828453302383423
Constrained beta: 7.109527587890625
Constrained gamma: 73.009033203125
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 8.338483810424805 500
training loss = 7.416914463043213 1000
training loss = 7.3438286781311035 1500
training loss = 7.297492980957031 2000
training loss = 7.23862886428833 2500
training loss = 7.161704063415527 3000
training loss = 7.055732250213623 3500
training loss = 6.895321846008301 4000
training loss = 6.613907337188721 4500
training loss = 6.006165027618408 5000
training loss = 4.5097503662109375 5500
training loss = 2.399942636489868 6000
reduced chi^2 level 2 = 2.3969032764434814
Constrained alpha: 3.8624725341796875
Constrained beta: 6.915100574493408
Constrained gamma: 72.18630981445312
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 8.3956937789917 500
training loss = 6.519089698791504 1000
training loss = 6.484776496887207 1500
training loss = 6.460880279541016 2000
training loss = 6.43056058883667 2500
training loss = 6.393013954162598 3000
training loss = 6.347177505493164 3500
training loss = 6.291569709777832 4000
training loss = 6.223906993865967 4500
training loss = 6.140468120574951 5000
training loss = 6.034960746765137 5500
training loss = 5.895988941192627 6000
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 14.428862571716309 500
training loss = 8.502951622009277 1000
training loss = 7.30654764175415 1500
training loss = 7.093809604644775 2000
training loss = 6.913949966430664 2500
training loss = 6.55588960647583 3000
training loss = 5.634355068206787 3500
training loss = 3.476682662963867 4000
training loss = 1.9660441875457764 4500
training loss = 1.5870786905288696 5000
training loss = 1.4864304065704346 5500
training loss = 1.4425952434539795 6000
reduced chi^2 level 2 = 1.442527413368225
Constrained alpha: 3.8617470264434814
Constrained beta: 7.0506181716918945
Constrained gamma: 72.00777435302734
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 27.384841918945312 500
training loss = 24.066049575805664 1000
training loss = 23.501707077026367 1500
training loss = 20.931217193603516 2000
training loss = 6.836634635925293 2500
training loss = 6.069584369659424 3000
training loss = 5.821050643920898 3500
training loss = 5.427969932556152 4000
training loss = 4.753203392028809 4500
training loss = 3.702477216720581 5000
training loss = 2.580489158630371 5500
training loss = 1.8870511054992676 6000
reduced chi^2 level 2 = 1.8861522674560547
Constrained alpha: 3.630868673324585
Constrained beta: 7.464532852172852
Constrained gamma: 73.33875274658203
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 11.16617488861084 500
training loss = 10.604775428771973 1000
training loss = 9.053060531616211 1500
training loss = 7.175693988800049 2000
training loss = 6.861405372619629 2500
training loss = 6.50205135345459 3000
training loss = 6.007236003875732 3500
training loss = 5.3244123458862305 4000
training loss = 4.380792140960693 4500
training loss = 3.1610920429229736 5000
training loss = 1.9502724409103394 5500
training loss = 1.418405532836914 6000
reduced chi^2 level 2 = 1.418140172958374
Constrained alpha: 3.796588897705078
Constrained beta: 7.295144081115723
Constrained gamma: 73.5904312133789
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 13.854902267456055 500
training loss = 7.8696393966674805 1000
training loss = 7.325275897979736 1500
training loss = 7.286905765533447 2000
training loss = 7.262654781341553 2500
training loss = 7.229893684387207 3000
training loss = 7.183032512664795 3500
training loss = 7.109775066375732 4000
training loss = 6.97275447845459 4500
training loss = 6.597047805786133 5000
training loss = 4.530740737915039 5500
training loss = 1.5161099433898926 6000
reduced chi^2 level 2 = 1.515297293663025
Constrained alpha: 3.827572822570801
Constrained beta: 6.956406593322754
Constrained gamma: 71.9367904663086
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 7.809307098388672 500
training loss = 7.403877258300781 1000
training loss = 7.356745719909668 1500
training loss = 7.325639247894287 2000
training loss = 7.286655902862549 2500
training loss = 7.233082294464111 3000
training loss = 7.149463176727295 3500
training loss = 6.984354019165039 4000
training loss = 6.476381778717041 4500
training loss = 4.460516452789307 5000
training loss = 2.2216708660125732 5500
training loss = 1.6631336212158203 6000
reduced chi^2 level 2 = 1.662570834159851
Constrained alpha: 3.865983009338379
Constrained beta: 6.814688205718994
Constrained gamma: 71.30699920654297
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 7.681342124938965 500
training loss = 7.452163219451904 1000
training loss = 7.373225688934326 1500
training loss = 7.342474937438965 2000
training loss = 7.307649612426758 2500
training loss = 7.25632381439209 3000
training loss = 7.173486709594727 3500
training loss = 7.014122486114502 4000
training loss = 6.617429733276367 4500
training loss = 5.681933403015137 5000
training loss = 3.9412686824798584 5500
training loss = 1.899183750152588 6000
reduced chi^2 level 2 = 1.8972795009613037
Constrained alpha: 3.8379852771759033
Constrained beta: 6.693388938903809
Constrained gamma: 70.78055572509766
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 9.241025924682617 500
training loss = 7.54337215423584 1000
training loss = 7.462600231170654 1500
training loss = 7.434956073760986 2000
training loss = 7.398433685302734 2500
training loss = 7.3465657234191895 3000
training loss = 7.264504432678223 3500
training loss = 7.092700481414795 4000
training loss = 6.458155632019043 4500
training loss = 3.888279914855957 5000
training loss = 1.7368872165679932 5500
training loss = 1.457200288772583 6000
reduced chi^2 level 2 = 1.456984519958496
Constrained alpha: 3.887603759765625
Constrained beta: 6.618061542510986
Constrained gamma: 70.19486236572266
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
training loss = 8.53609561920166 500
training loss = 7.570345401763916 1000
training loss = 7.425027847290039 1500
training loss = 7.267772674560547 2000
training loss = 7.061649322509766 2500
training loss = 6.796050071716309 3000
training loss = 6.454941749572754 3500
training loss = 6.007961273193359 4000
training loss = 5.395909786224365 4500
training loss = 4.528042793273926 5000
training loss = 3.3759543895721436 5500
training loss = 2.23443603515625 6000
reduced chi^2 level 2 = 2.23252534866333
Constrained alpha: 3.8365023136138916
Constrained beta: 6.819038391113281
Constrained gamma: 71.69586944580078
(1, 15)
(1, 0)
data before
[ 0.28392902  2.60326489  5.2211792   7.19104346  8.59665625  9.45759766
 10.00161426 10.30683008 10.38086328 10.39964355 10.2263584  10.03318555
  9.77004004  9.50897949  9.12554199  8.70178223  8.44125293  8.0368667
  7.71856006  7.30564746  7.02591748  6.7341875   6.36997949  6.11599561
  5.78784326  5.51510303  5.29743457  5.05434277  4.74014893  4.56041113
  4.29733301  4.08112451  3.90394189  3.70491553  3.5341228   3.33250244
  3.12305981  2.99898071  2.85930908  2.72594385  2.55420239  2.43148901
  2.30331372  2.19018872  2.0466095   1.97796545  1.87214612  1.74818176
  1.65385974  1.58134058  1.46910034  1.37214075  1.28902319  1.21795886
  1.15482336  1.07299768  1.00046094  0.95060071  0.86308881  0.85152399
  0.7936637   0.75127496  0.6719801   0.61297534  0.57909485  0.53694495
  0.49439246  0.46684427  0.44663306  0.41002191  0.37233636  0.32457562
  0.30595123  0.28160892  0.26991013  0.24864568  0.21515633  0.2064852
  0.18161758  0.15422755  0.14447073  0.12943889  0.11509945  0.10520933
  0.09529341  0.08223444  0.07355038  0.06046867  0.05689466  0.04752491
  0.0456788   0.04136079  0.03637111  0.02940079  0.02863137  0.02378897
  0.02048417  0.01569818  0.01431756  0.01175551]
48
data after
[23.896072814941405, 29.7660419921875, 20.7805068359375, 20.2595439453125, 28.4045615234375, 25.17990185546875, 22.050125, 25.008005859375004, 20.607029296874998, 20.54772607421875, 21.12812109375, 38.54882556533812]
59
data,sig_tot
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
[23.89607281 29.76604199 20.78050684 20.25954395 28.40456152 25.17990186
 22.050125   25.00800586 20.6070293  20.54772607 21.12812109 38.54882557
 22.4344271  20.42529504 23.02416217]
4.284251512288666 7.033052788641758 75.46476915298572
val isze = 0
idinces = [ 3  7 12  6  8  2 10  5 11 14  1  0  4 13  9]
(1, 15)
(1, 0)
