data before
[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 4.59863711e+03 4.68015448e+03 4.75745306e+03 4.89189955e+03
 5.03306554e+03 5.25084451e+03 5.31924965e+03 5.30780862e+03
 5.49884518e+03 5.58969112e+03 5.62078229e+03 5.77803005e+03
 5.88141140e+03 5.88125978e+03 6.05927287e+03 6.13031550e+03
 6.21215635e+03 6.22466275e+03 6.28964100e+03 6.30713567e+03
 6.40962233e+03 6.46794368e+03 6.49701160e+03 6.53896370e+03
 6.53845880e+03 6.53567124e+03 6.44810357e+03 6.45820672e+03
 6.38706359e+03 6.38775651e+03 6.34925011e+03 6.28975769e+03
 6.24199150e+03 6.15593398e+03 5.98687512e+03 5.89776760e+03
 5.80819436e+03 5.70674893e+03 5.61362163e+03 5.45449633e+03
 5.27910895e+03 5.10099627e+03 4.88733892e+03 4.75496746e+03
 4.58522449e+03 4.39909823e+03 4.21432177e+03 4.01963689e+03
 3.82568239e+03 3.63143648e+03 3.42217829e+03 3.24302173e+03
 3.06838529e+03 2.82961444e+03 2.63834916e+03 2.47086875e+03
 2.26008073e+03 2.07153087e+03 1.91903063e+03 1.77062672e+03
 1.60161807e+03 1.46477172e+03 1.31482987e+03 1.16991884e+03
 1.03072866e+03 9.08732083e+02 8.01859410e+02 7.14303127e+02
 6.25649099e+02 5.29022549e+02 4.48027815e+02 3.75918663e+02
 3.08871662e+02 2.58008330e+02 2.11075907e+02 1.71977942e+02
 1.36271458e+02 1.01400294e+02 7.56636555e+01 5.34445444e+01
 3.81358484e+01 3.06122499e+01 2.46286677e+01 1.96825222e+01
 1.43512283e+01 1.02373550e+01 7.25445310e+00 4.75220210e+00
 3.46055415e+00 1.26075080e+00 4.40917380e-02 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00]
13
data after
[4598.637112035384, 4680.154479623603, 4757.453058924168, 4891.899553467534, 5033.065538444174, 5250.844508347476, 5319.249647355908, 5307.808624122501, 5498.8451763690655, 5589.691123323983, 5620.782289333134, 5778.03004530935, 5881.411402803338, 5881.259776552001, 6059.272868685972, 6130.315497527697, 6212.156347580102, 6224.662749256414, 6289.640998493531, 6307.135673671542, 6409.622332909766, 6467.943678683994, 6497.011599509635, 6538.963699182047, 6538.458798296524, 6535.671242347543, 6448.103568769147, 6458.206720188486, 6387.063587725059, 6387.756505370097, 6349.250114943531, 6289.757692343994, 6241.991496195412, 6155.933976227414, 5986.875123412361, 5897.767601440559, 5808.194360695562, 5706.748933532996, 5613.621626383167, 5454.4963259615315, 5279.108954913488, 5100.996268306558, 4887.338919196416, 4754.9674595152, 4585.2244907523245, 4399.098227920245, 4214.321766575668, 4019.6368906551497, 3825.682390795968, 3631.436478807638, 3422.1782904571746, 3243.021732848288, 3068.385292772373, 2829.6144403244302, 2638.349158203089, 2470.868747005664, 2260.0807280632694, 2071.5308676132636, 1919.0306260709006, 1770.6267206609336, 1601.6180686170028, 1464.7717208040392, 1314.8298664835588, 1169.9188430405156, 1030.728657142295, 908.7320834636424, 801.8594095709651, 714.3031271689983, 625.6490990497571, 529.0225487287121, 448.02781538345835, 375.9186633860295, 308.87166166488817, 258.00833044366084, 211.0759065107323, 171.97794193324273, 136.27145767929665, 101.40029422789658, 75.66365552266346, 53.44454437489857, 38.135848364429506, 30.61224985996854, 24.62866771746742, 34.033750557709794, 27.009406838029562]
16
data,sig_tot
[4598.63711204 4680.15447962 4757.45305892 4891.89955347 5033.06553844
 5250.84450835 5319.24964736 5307.80862412 5498.84517637 5589.69112332
 5620.78228933 5778.03004531 5881.4114028  5881.25977655 6059.27286869
 6130.31549753 6212.15634758 6224.66274926 6289.64099849 6307.13567367
 6409.62233291 6467.94367868 6497.01159951 6538.96369918 6538.4587983
 6535.67124235 6448.10356877 6458.20672019 6387.06358773 6387.75650537
 6349.25011494 6289.75769234 6241.9914962  6155.93397623 5986.87512341
 5897.76760144 5808.1943607  5706.74893353 5613.62162638 5454.49632596
 5279.10895491 5100.99626831 4887.3389192  4754.96745952 4585.22449075
 4399.09822792 4214.32176658 4019.63689066 3825.6823908  3631.43647881
 3422.17829046 3243.02173285 3068.38529277 2829.61444032 2638.3491582
 2470.86874701 2260.08072806 2071.53086761 1919.03062607 1770.62672066
 1601.61806862 1464.7717208  1314.82986648 1169.91884304 1030.72865714
  908.73208346  801.85940957  714.30312717  625.64909905  529.02254873
  448.02781538  375.91866339  308.87166166  258.00833044  211.07590651
  171.97794193  136.27145768  101.40029423   75.66365552   53.44454437
   38.13584836   30.61224986   24.62866772   34.03375056   27.00940684
  832.72626449  873.99479789  909.19676465  941.47448005  962.13522622
  993.40509244 1039.66626667 1088.05066004 1112.54806984 1128.18529091
 1170.71331392 1195.06458388 1253.33901639 1249.67593099 1317.22359877
 1338.19033244 1348.72499168 1381.03710185 1424.19803751 1433.22419144
 1455.88636466 1483.04192217 1499.94546688 1531.42364049 1530.57360366
 1516.92433255 1540.61663293 1546.63280156 1543.34752414 1549.76498637
 1546.32171994 1536.78196995 1539.29973856 1518.16473872 1507.62114674
 1473.99624591 1450.69937823 1425.60352814 1383.75766883 1370.8740982
 1336.89446446 1297.4037168  1248.09419384 1206.40513378 1173.84396623
 1113.88471416 1080.12537513 1031.05072614  985.03145416  932.52276845
  881.56528629  828.86028791  784.14566135  730.99829137  685.49339364
  630.19345955  581.93435263  539.03486413  490.91769247  448.82323181
  408.53215009  364.51893048  329.02110108  289.65975719  255.13824845
  222.38076109  195.38120612  170.46178533  146.75636458  122.80164965
  102.42781658   82.72280092   66.808603     53.48717775   44.68730108
   36.27075316   27.73754015   20.56293034   23.81160336   26.18315604]
[4598.63711204 4680.15447962 4757.45305892 4891.89955347 5033.06553844
 5250.84450835 5319.24964736 5307.80862412 5498.84517637 5589.69112332
 5620.78228933 5778.03004531 5881.4114028  5881.25977655 6059.27286869
 6130.31549753 6212.15634758 6224.66274926 6289.64099849 6307.13567367
 6409.62233291 6467.94367868 6497.01159951 6538.96369918 6538.4587983
 6535.67124235 6448.10356877 6458.20672019 6387.06358773 6387.75650537
 6349.25011494 6289.75769234 6241.9914962  6155.93397623 5986.87512341
 5897.76760144 5808.1943607  5706.74893353 5613.62162638 5454.49632596
 5279.10895491 5100.99626831 4887.3389192  4754.96745952 4585.22449075
 4399.09822792 4214.32176658 4019.63689066 3825.6823908  3631.43647881
 3422.17829046 3243.02173285 3068.38529277 2829.61444032 2638.3491582
 2470.86874701 2260.08072806 2071.53086761 1919.03062607 1770.62672066
 1601.61806862 1464.7717208  1314.82986648 1169.91884304 1030.72865714
  908.73208346  801.85940957  714.30312717  625.64909905  529.02254873
  448.02781538  375.91866339  308.87166166  258.00833044  211.07590651
  171.97794193  136.27145768  101.40029423   75.66365552   53.44454437
   38.13584836   30.61224986   24.62866772   34.03375056   27.00940684
  832.72626449  873.99479789  909.19676465  941.47448005  962.13522622
  993.40509244 1039.66626667 1088.05066004 1112.54806984 1128.18529091
 1170.71331392 1195.06458388 1253.33901639 1249.67593099 1317.22359877
 1338.19033244 1348.72499168 1381.03710185 1424.19803751 1433.22419144
 1455.88636466 1483.04192217 1499.94546688 1531.42364049 1530.57360366
 1516.92433255 1540.61663293 1546.63280156 1543.34752414 1549.76498637
 1546.32171994 1536.78196995 1539.29973856 1518.16473872 1507.62114674
 1473.99624591 1450.69937823 1425.60352814 1383.75766883 1370.8740982
 1336.89446446 1297.4037168  1248.09419384 1206.40513378 1173.84396623
 1113.88471416 1080.12537513 1031.05072614  985.03145416  932.52276845
  881.56528629  828.86028791  784.14566135  730.99829137  685.49339364
  630.19345955  581.93435263  539.03486413  490.91769247  448.82323181
  408.53215009  364.51893048  329.02110108  289.65975719  255.13824845
  222.38076109  195.38120612  170.46178533  146.75636458  122.80164965
  102.42781658   82.72280092   66.808603     53.48717775   44.68730108
   36.27075316   27.73754015   20.56293034   23.81160336   26.18315604]
2.677155552962929 5.653860672598676 55.81195598645887
val isze = 16
idinces = [ 43  63  87  20 129  68  98 104  66 133 145  10 136  24  61 155  58  70
  52 105   1  35  99  39  19  47  49 106  21  60 103 132 138  97 128 141
  69   2  56 135  38  76 116 118 131  72  82  59  55 134  83  26 137  67
  41  78  32 161 158  48 108  25  53  90 109  51  14 150  29   3 159 114
 153  37 154 152  45 144  81  42  79 130 143  12 110 124  85   6  91  95
 163 151  34 140  50 102 101 112   4   5  44 111  96  84 142 119  75   7
  46  17 121 117  71  80 127 162 164 146  74  28  11 120  94  23  22 148
  93  18  27  36  57  31  65  89  30  86  92 126  13  77 147 149  33  62
 122 107  88  54 139 100  16 115  40   0  73   8 160 157 156 123 113  64
  15 125   9]
we are doing training validation split
training loss = 14.36204719543457 500
val loss = 14.042585372924805
training loss = 12.448373794555664 1000
val loss = 17.177661895751953
training loss = 12.233959197998047 1500
val loss = 18.080476760864258
training loss = 3.7922232151031494 2000
val loss = 4.690308094024658
training loss = 2.5491108894348145 2500
val loss = 2.9354844093322754
training loss = 2.372690200805664 3000
val loss = 2.630434989929199
training loss = 2.3319740295410156 3500
val loss = 2.667431116104126
training loss = 2.3065497875213623 4000
val loss = 2.703707695007324
training loss = 2.289639949798584 4500
val loss = 2.7232651710510254
training loss = 2.2747437953948975 5000
val loss = 2.7280750274658203
training loss = 2.2599401473999023 5500
val loss = 2.7217965126037598
training loss = 2.2435295581817627 6000
val loss = 2.7167162895202637
training loss = 2.225109100341797 6500
val loss = 2.681666374206543
training loss = 2.207491636276245 7000
val loss = 2.655250072479248
training loss = 2.1890299320220947 7500
val loss = 2.618405818939209
training loss = 2.172227621078491 8000
val loss = 2.5825159549713135
training loss = 2.157949209213257 8500
val loss = 2.548445701599121
training loss = 2.153008222579956 9000
val loss = 2.5224077701568604
training loss = 2.138171672821045 9500
val loss = 2.477663993835449
training loss = 2.1274101734161377 10000
val loss = 2.477752685546875
training loss = 2.1599621772766113 10500
val loss = 2.520185947418213
training loss = 2.1148087978363037 11000
val loss = 2.4602785110473633
training loss = 2.1114587783813477 11500
val loss = 2.4515914916992188
training loss = 2.1379940509796143 12000
val loss = 2.5158677101135254
training loss = 2.100267171859741 12500
val loss = 2.4429376125335693
training loss = 2.095696210861206 13000
val loss = 2.443925142288208
training loss = 2.097027063369751 13500
val loss = 2.451066493988037
training loss = 2.104391098022461 14000
val loss = 2.4473929405212402
training loss = 2.0755064487457275 14500
val loss = 2.438117504119873
training loss = 2.064248561859131 15000
val loss = 2.4362916946411133
training loss = 2.2500782012939453 15500
val loss = 2.61340594291687
training loss = 2.0625510215759277 16000
val loss = 2.4238433837890625
training loss = 2.0465891361236572 16500
val loss = 2.384474515914917
training loss = 2.0576016902923584 17000
val loss = 2.4072625637054443
training loss = 2.029085159301758 17500
val loss = 2.3671796321868896
training loss = 2.025498390197754 18000
val loss = 2.353046417236328
training loss = 2.026341199874878 18500
val loss = 2.3839945793151855
training loss = 2.011957883834839 19000
val loss = 2.3319897651672363
training loss = 2.00738787651062 19500
val loss = 2.319303512573242
training loss = 3.7250559329986572 20000
val loss = 3.977719306945801
training loss = 2.0147523880004883 20500
val loss = 2.3274409770965576
training loss = 1.9983782768249512 21000
val loss = 2.3231778144836426
training loss = 1.9947069883346558 21500
val loss = 2.309915065765381
training loss = 6.039565563201904 22000
val loss = 5.9255690574646
training loss = 2.002812623977661 22500
val loss = 2.3091444969177246
training loss = 1.9900517463684082 23000
val loss = 2.3312575817108154
training loss = 1.9850943088531494 23500
val loss = 2.31044340133667
training loss = 1.9818223714828491 24000
val loss = 2.3014168739318848
training loss = 1.9782768487930298 24500
val loss = 2.2904469966888428
training loss = 1.9744852781295776 25000
val loss = 2.2825841903686523
training loss = 1.9695711135864258 25500
val loss = 2.273507595062256
training loss = 2.0472404956817627 26000
val loss = 2.2577924728393555
training loss = 1.9627091884613037 26500
val loss = 2.2642505168914795
training loss = 1.9220517873764038 27000
val loss = 2.2385048866271973
training loss = 1.9013946056365967 27500
val loss = 2.218301296234131
training loss = 1.8930028676986694 28000
val loss = 2.2133843898773193
training loss = 1.8888572454452515 28500
val loss = 2.212667226791382
training loss = 2.1374170780181885 29000
val loss = 2.4119362831115723
training loss = 1.8824868202209473 29500
val loss = 2.203461170196533
training loss = 1.900742769241333 30000
val loss = 2.1425490379333496
reduced chi^2 level 2 = 1.8864471912384033
Constrained alpha: 2.4045097827911377
Constrained beta: 2.1640255451202393
Constrained gamma: 23.70050811767578
(1, 149)
(1, 16)
