data before
[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 4.59863711e+03 4.68015448e+03 4.75745306e+03 4.89189955e+03
 5.03306554e+03 5.25084451e+03 5.31924965e+03 5.30780862e+03
 5.49884518e+03 5.58969112e+03 5.62078229e+03 5.77803005e+03
 5.88141140e+03 5.88125978e+03 6.05927287e+03 6.13031550e+03
 6.21215635e+03 6.22466275e+03 6.28964100e+03 6.30713567e+03
 6.40962233e+03 6.46794368e+03 6.49701160e+03 6.53896370e+03
 6.53845880e+03 6.53567124e+03 6.44810357e+03 6.45820672e+03
 6.38706359e+03 6.38775651e+03 6.34925011e+03 6.28975769e+03
 6.24199150e+03 6.15593398e+03 5.98687512e+03 5.89776760e+03
 5.80819436e+03 5.70674893e+03 5.61362163e+03 5.45449633e+03
 5.27910895e+03 5.10099627e+03 4.88733892e+03 4.75496746e+03
 4.58522449e+03 4.39909823e+03 4.21432177e+03 4.01963689e+03
 3.82568239e+03 3.63143648e+03 3.42217829e+03 3.24302173e+03
 3.06838529e+03 2.82961444e+03 2.63834916e+03 2.47086875e+03
 2.26008073e+03 2.07153087e+03 1.91903063e+03 1.77062672e+03
 1.60161807e+03 1.46477172e+03 1.31482987e+03 1.16991884e+03
 1.03072866e+03 9.08732083e+02 8.01859410e+02 7.14303127e+02
 6.25649099e+02 5.29022549e+02 4.48027815e+02 3.75918663e+02
 3.08871662e+02 2.58008330e+02 2.11075907e+02 1.71977942e+02
 1.36271458e+02 1.01400294e+02 7.56636555e+01 5.34445444e+01
 3.81358484e+01 3.06122499e+01 2.46286677e+01 1.96825222e+01
 1.43512283e+01 1.02373550e+01 7.25445310e+00 4.75220210e+00
 3.46055415e+00 1.26075080e+00 4.40917380e-02 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00]
13
data after
[4598.637112035384, 4680.154479623603, 4757.453058924168, 4891.899553467534, 5033.065538444174, 5250.844508347476, 5319.249647355908, 5307.808624122501, 5498.8451763690655, 5589.691123323983, 5620.782289333134, 5778.03004530935, 5881.411402803338, 5881.259776552001, 6059.272868685972, 6130.315497527697, 6212.156347580102, 6224.662749256414, 6289.640998493531, 6307.135673671542, 6409.622332909766, 6467.943678683994, 6497.011599509635, 6538.963699182047, 6538.458798296524, 6535.671242347543, 6448.103568769147, 6458.206720188486, 6387.063587725059, 6387.756505370097, 6349.250114943531, 6289.757692343994, 6241.991496195412, 6155.933976227414, 5986.875123412361, 5897.767601440559, 5808.194360695562, 5706.748933532996, 5613.621626383167, 5454.4963259615315, 5279.108954913488, 5100.996268306558, 4887.338919196416, 4754.9674595152, 4585.2244907523245, 4399.098227920245, 4214.321766575668, 4019.6368906551497, 3825.682390795968, 3631.436478807638, 3422.1782904571746, 3243.021732848288, 3068.385292772373, 2829.6144403244302, 2638.349158203089, 2470.868747005664, 2260.0807280632694, 2071.5308676132636, 1919.0306260709006, 1770.6267206609336, 1601.6180686170028, 1464.7717208040392, 1314.8298664835588, 1169.9188430405156, 1030.728657142295, 908.7320834636424, 801.8594095709651, 714.3031271689983, 625.6490990497571, 529.0225487287121, 448.02781538345835, 375.9186633860295, 308.87166166488817, 258.00833044366084, 211.0759065107323, 171.97794193324273, 136.27145767929665, 101.40029422789658, 75.66365552266346, 53.44454437489857, 38.135848364429506, 30.61224985996854, 24.62866771746742, 34.033750557709794, 27.009406838029562]
16
data,sig_tot
[4598.63711204 4680.15447962 4757.45305892 4891.89955347 5033.06553844
 5250.84450835 5319.24964736 5307.80862412 5498.84517637 5589.69112332
 5620.78228933 5778.03004531 5881.4114028  5881.25977655 6059.27286869
 6130.31549753 6212.15634758 6224.66274926 6289.64099849 6307.13567367
 6409.62233291 6467.94367868 6497.01159951 6538.96369918 6538.4587983
 6535.67124235 6448.10356877 6458.20672019 6387.06358773 6387.75650537
 6349.25011494 6289.75769234 6241.9914962  6155.93397623 5986.87512341
 5897.76760144 5808.1943607  5706.74893353 5613.62162638 5454.49632596
 5279.10895491 5100.99626831 4887.3389192  4754.96745952 4585.22449075
 4399.09822792 4214.32176658 4019.63689066 3825.6823908  3631.43647881
 3422.17829046 3243.02173285 3068.38529277 2829.61444032 2638.3491582
 2470.86874701 2260.08072806 2071.53086761 1919.03062607 1770.62672066
 1601.61806862 1464.7717208  1314.82986648 1169.91884304 1030.72865714
  908.73208346  801.85940957  714.30312717  625.64909905  529.02254873
  448.02781538  375.91866339  308.87166166  258.00833044  211.07590651
  171.97794193  136.27145768  101.40029423   75.66365552   53.44454437
   38.13584836   30.61224986   24.62866772   34.03375056   27.00940684
  832.72626449  873.99479789  909.19676465  941.47448005  962.13522622
  993.40509244 1039.66626667 1088.05066004 1112.54806984 1128.18529091
 1170.71331392 1195.06458388 1253.33901639 1249.67593099 1317.22359877
 1338.19033244 1348.72499168 1381.03710185 1424.19803751 1433.22419144
 1455.88636466 1483.04192217 1499.94546688 1531.42364049 1530.57360366
 1516.92433255 1540.61663293 1546.63280156 1543.34752414 1549.76498637
 1546.32171994 1536.78196995 1539.29973856 1518.16473872 1507.62114674
 1473.99624591 1450.69937823 1425.60352814 1383.75766883 1370.8740982
 1336.89446446 1297.4037168  1248.09419384 1206.40513378 1173.84396623
 1113.88471416 1080.12537513 1031.05072614  985.03145416  932.52276845
  881.56528629  828.86028791  784.14566135  730.99829137  685.49339364
  630.19345955  581.93435263  539.03486413  490.91769247  448.82323181
  408.53215009  364.51893048  329.02110108  289.65975719  255.13824845
  222.38076109  195.38120612  170.46178533  146.75636458  122.80164965
  102.42781658   82.72280092   66.808603     53.48717775   44.68730108
   36.27075316   27.73754015   20.56293034   23.81160336   26.18315604]
[4598.63711204 4680.15447962 4757.45305892 4891.89955347 5033.06553844
 5250.84450835 5319.24964736 5307.80862412 5498.84517637 5589.69112332
 5620.78228933 5778.03004531 5881.4114028  5881.25977655 6059.27286869
 6130.31549753 6212.15634758 6224.66274926 6289.64099849 6307.13567367
 6409.62233291 6467.94367868 6497.01159951 6538.96369918 6538.4587983
 6535.67124235 6448.10356877 6458.20672019 6387.06358773 6387.75650537
 6349.25011494 6289.75769234 6241.9914962  6155.93397623 5986.87512341
 5897.76760144 5808.1943607  5706.74893353 5613.62162638 5454.49632596
 5279.10895491 5100.99626831 4887.3389192  4754.96745952 4585.22449075
 4399.09822792 4214.32176658 4019.63689066 3825.6823908  3631.43647881
 3422.17829046 3243.02173285 3068.38529277 2829.61444032 2638.3491582
 2470.86874701 2260.08072806 2071.53086761 1919.03062607 1770.62672066
 1601.61806862 1464.7717208  1314.82986648 1169.91884304 1030.72865714
  908.73208346  801.85940957  714.30312717  625.64909905  529.02254873
  448.02781538  375.91866339  308.87166166  258.00833044  211.07590651
  171.97794193  136.27145768  101.40029423   75.66365552   53.44454437
   38.13584836   30.61224986   24.62866772   34.03375056   27.00940684
  832.72626449  873.99479789  909.19676465  941.47448005  962.13522622
  993.40509244 1039.66626667 1088.05066004 1112.54806984 1128.18529091
 1170.71331392 1195.06458388 1253.33901639 1249.67593099 1317.22359877
 1338.19033244 1348.72499168 1381.03710185 1424.19803751 1433.22419144
 1455.88636466 1483.04192217 1499.94546688 1531.42364049 1530.57360366
 1516.92433255 1540.61663293 1546.63280156 1543.34752414 1549.76498637
 1546.32171994 1536.78196995 1539.29973856 1518.16473872 1507.62114674
 1473.99624591 1450.69937823 1425.60352814 1383.75766883 1370.8740982
 1336.89446446 1297.4037168  1248.09419384 1206.40513378 1173.84396623
 1113.88471416 1080.12537513 1031.05072614  985.03145416  932.52276845
  881.56528629  828.86028791  784.14566135  730.99829137  685.49339364
  630.19345955  581.93435263  539.03486413  490.91769247  448.82323181
  408.53215009  364.51893048  329.02110108  289.65975719  255.13824845
  222.38076109  195.38120612  170.46178533  146.75636458  122.80164965
  102.42781658   82.72280092   66.808603     53.48717775   44.68730108
   36.27075316   27.73754015   20.56293034   23.81160336   26.18315604]
2.806564280198243 2.092598197018567 9.079582288734178
val isze = 16
idinces = [ 43  63  87  20 129  68  98 104  66 133 145  10 136  24  61 155  58  70
  52 105   1  35  99  39  19  47  49 106  21  60 103 132 138  97 128 141
  69   2  56 135  38  76 116 118 131  72  82  59  55 134  83  26 137  67
  41  78  32 161 158  48 108  25  53  90 109  51  14 150  29   3 159 114
 153  37 154 152  45 144  81  42  79 130 143  12 110 124  85   6  91  95
 163 151  34 140  50 102 101 112   4   5  44 111  96  84 142 119  75   7
  46  17 121 117  71  80 127 162 164 146  74  28  11 120  94  23  22 148
  93  18  27  36  57  31  65  89  30  86  92 126  13  77 147 149  33  62
 122 107  88  54 139 100  16 115  40   0  73   8 160 157 156 123 113  64
  15 125   9]
we are doing training validation split
training loss = 22.503707885742188 500
val loss = 12.815987586975098
training loss = 13.246306419372559 1000
val loss = 13.030220031738281
training loss = 12.392203330993652 1500
val loss = 15.163856506347656
training loss = 11.85659122467041 2000
val loss = 15.341080665588379
training loss = 11.29903793334961 2500
val loss = 15.329204559326172
training loss = 10.932570457458496 3000
val loss = 15.534516334533691
training loss = 10.773147583007812 3500
val loss = 15.689486503601074
training loss = 10.536723136901855 4000
val loss = 15.525741577148438
training loss = 2.393789291381836 4500
val loss = 2.283097267150879
training loss = 2.0896599292755127 5000
val loss = 2.316849946975708
training loss = 2.0493545532226562 5500
val loss = 2.2949118614196777
training loss = 2.0215439796447754 6000
val loss = 2.2120132446289062
training loss = 1.9991044998168945 6500
val loss = 2.1434779167175293
training loss = 1.980049729347229 7000
val loss = 2.082803249359131
training loss = 1.9648486375808716 7500
val loss = 2.041351079940796
training loss = 1.953482985496521 8000
val loss = 2.0161490440368652
training loss = 1.943999171257019 8500
val loss = 1.9985899925231934
training loss = 1.936405897140503 9000
val loss = 1.9887034893035889
training loss = 1.9305102825164795 9500
val loss = 1.9816572666168213
training loss = 1.925388216972351 10000
val loss = 1.9775028228759766
training loss = 1.9212654829025269 10500
val loss = 1.9752696752548218
training loss = 1.917770504951477 11000
val loss = 1.9718774557113647
training loss = 1.915291666984558 11500
val loss = 1.9967613220214844
training loss = 1.92755126953125 12000
val loss = 1.8430544137954712
training loss = 2.049459457397461 12500
val loss = 1.6686052083969116
training loss = 1.9158750772476196 13000
val loss = 1.8931782245635986
training loss = 2.3828444480895996 13500
val loss = 3.2230029106140137
training loss = 1.9063124656677246 14000
val loss = 1.9748444557189941
training loss = 1.905376672744751 14500
val loss = 1.976455807685852
training loss = 1.904457926750183 15000
val loss = 1.9840446710586548
training loss = 1.9039957523345947 15500
val loss = 1.9530041217803955
training loss = 1.9027212858200073 16000
val loss = 1.975673794746399
training loss = 1.9021836519241333 16500
val loss = 1.958266258239746
training loss = 1.9011001586914062 17000
val loss = 1.9751043319702148
training loss = 1.9003986120224 17500
val loss = 1.977436900138855
training loss = 1.8996692895889282 18000
val loss = 1.9764102697372437
training loss = 1.8989077806472778 18500
val loss = 1.974561095237732
training loss = 1.8982466459274292 19000
val loss = 1.9737548828125
training loss = 1.9324531555175781 19500
val loss = 1.7773187160491943
training loss = 2.097862482070923 20000
val loss = 2.715257167816162
training loss = 1.934100866317749 20500
val loss = 1.791975498199463
training loss = 1.8957719802856445 21000
val loss = 1.9705798625946045
training loss = 1.895088791847229 21500
val loss = 1.9699863195419312
training loss = 1.8944722414016724 22000
val loss = 1.9683468341827393
training loss = 1.8937922716140747 22500
val loss = 1.9669249057769775
training loss = 1.893097996711731 23000
val loss = 1.966529130935669
training loss = 1.892390489578247 23500
val loss = 1.9644958972930908
training loss = 1.891735553741455 24000
val loss = 1.9651484489440918
training loss = 1.8910659551620483 24500
val loss = 1.957951545715332
training loss = 1.890565037727356 25000
val loss = 1.9436920881271362
training loss = 1.8897287845611572 25500
val loss = 1.961038589477539
training loss = 1.889018177986145 26000
val loss = 1.95973539352417
training loss = 1.8883330821990967 26500
val loss = 1.9590798616409302
training loss = 1.8875917196273804 27000
val loss = 1.9578595161437988
training loss = 1.887070894241333 27500
val loss = 1.9758751392364502
training loss = 2.8816425800323486 28000
val loss = 4.033164024353027
training loss = 3.273394823074341 28500
val loss = 1.777818202972412
training loss = 1.9848666191101074 29000
val loss = 1.657651662826538
training loss = 3.9805827140808105 29500
val loss = 2.070730447769165
training loss = 1.889846682548523 30000
val loss = 2.055610418319702
reduced chi^2 level 2 = 1.893562912940979
Constrained alpha: 2.291750431060791
Constrained beta: 3.3200290203094482
Constrained gamma: 9.937665939331055
(1, 149)
(1, 16)
