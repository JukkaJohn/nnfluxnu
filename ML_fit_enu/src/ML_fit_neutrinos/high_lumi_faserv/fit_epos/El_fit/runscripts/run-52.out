data before
[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 1.49062519e+02 1.67988628e+02 1.84756801e+02 1.99295740e+02
 2.08864602e+02 2.10892075e+02 2.05316543e+02 1.91526206e+02
 1.70422482e+02 1.43531808e+02 1.12766530e+02 8.29920548e+01
 5.87078476e+01 3.59768908e+01 1.80225255e+01 6.48677791e+00
 1.53443149e+00 1.42783723e-01 0.00000000e+00 0.00000000e+00
 0.00000000e+00]
5
data after
[149.06251885022414, 167.98862759559862, 184.75680104024315, 199.29574034196307, 208.86460212845705, 210.89207494948326, 205.3165431855517, 191.52620601430385, 170.42248197293986, 143.53180819428323, 112.76653015785716, 82.992054832881, 58.70784764996863, 35.97689084691096, 26.18651865839047]
8
data,sig_tot
[149.06251885 167.9886276  184.75680104 199.29574034 208.86460213
 210.89207495 205.31654319 191.52620601 170.42248197 143.53180819
 112.76653016  82.99205483  58.70784765  35.97689085  26.18651866
  25.01956498  29.76566371  34.57853534  39.0537924   42.78745488
  45.03327904  45.07523072  43.28156672  39.17596164  33.34568609
  25.6385597   45.33953963]
[149.06251885 167.9886276  184.75680104 199.29574034 208.86460213
 210.89207495 205.31654319 191.52620601 170.42248197 143.53180819
 112.76653016  82.99205483  58.70784765  35.97689085  26.18651866
  25.01956498  29.76566371  34.57853534  39.0537924   42.78745488
  45.03327904  45.07523072  43.28156672  39.17596164  33.34568609
  25.6385597   45.33953963]
4.094250737312221 4.778020376185763 67.0421864035745
val isze = 0
idinces = [ 7  5 18 21 11  1  2 12 24 14 13 20  3 25  6 19 10 23 26  8 22 16 17  0
 15  4  9]
training loss = 17.903532028198242 500
training loss = 14.746984481811523 1000
training loss = 10.395854949951172 1500
training loss = 5.805974960327148 2000
training loss = 3.834599018096924 2500
training loss = 3.6672539710998535 3000
training loss = 3.614743947982788 3500
training loss = 3.558448076248169 4000
training loss = 3.4984521865844727 4500
training loss = 3.4354946613311768 5000
(1, 27)
(1, 0)
