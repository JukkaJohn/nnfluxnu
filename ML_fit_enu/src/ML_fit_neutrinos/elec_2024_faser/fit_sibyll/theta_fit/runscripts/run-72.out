data before
[1.09320972e+00 5.74235156e+00 9.54486621e+00 1.17265195e+01
 1.29260908e+01 1.36684707e+01 1.39244922e+01 1.36999912e+01
 1.36046475e+01 1.31748730e+01 1.27765322e+01 1.21843477e+01
 1.16747559e+01 1.11732148e+01 1.06282178e+01 1.00439844e+01
 9.54627930e+00 9.05142871e+00 8.56875684e+00 8.16751953e+00
 7.71184229e+00 7.24854736e+00 6.82743555e+00 6.53336621e+00
 6.17315430e+00 5.86468750e+00 5.49035010e+00 5.17557129e+00
 4.91877002e+00 4.64413330e+00 4.38263428e+00 4.17088330e+00
 3.96015112e+00 3.76726514e+00 3.57789673e+00 3.34148828e+00
 3.14132080e+00 3.03223145e+00 2.85318970e+00 2.69971509e+00
 2.54149463e+00 2.40267065e+00 2.26637109e+00 2.16974194e+00
 2.04004187e+00 1.91766931e+00 1.79150598e+00 1.70389294e+00
 1.60069031e+00 1.51870691e+00 1.41303723e+00 1.34390930e+00
 1.27982910e+00 1.17997583e+00 1.11654395e+00 1.06011072e+00
 9.88706055e-01 9.10417603e-01 8.59332275e-01 8.17088806e-01
 7.47596313e-01 6.97496765e-01 6.70395325e-01 5.75663635e-01
 5.53416748e-01 5.17966797e-01 4.59969849e-01 4.39890259e-01
 4.06600922e-01 3.83332184e-01 3.69296722e-01 3.27286774e-01
 2.98432861e-01 2.65635559e-01 2.42866760e-01 2.28603226e-01
 2.04875061e-01 1.96520447e-01 1.64914810e-01 1.52460953e-01
 1.37529556e-01 1.28927032e-01 1.05939339e-01 1.09737061e-01
 9.32269821e-02 8.71234818e-02 8.00198669e-02 6.64396820e-02
 5.70163116e-02 5.04421539e-02 4.70867271e-02 4.41799088e-02
 3.48043594e-02 2.96167107e-02 2.69011631e-02 2.25756569e-02
 1.89036942e-02 1.74839306e-02 1.41822081e-02 1.20798979e-02]
41
data after
[28.106947021484373, 26.594561523437502, 27.6244833984375, 26.7795205078125, 24.9608798828125, 22.847970703125, 20.6722021484375, 27.16646484375, 23.127909179687503, 25.398643554687503, 20.22882470703125, 23.200318847656252, 21.106735351562502, 30.628895883560183]
79
data,sig_tot
[28.10694702 26.59456152 27.6244834  26.77952051 24.96087988 22.8479707
 20.67220215 27.16646484 23.12790918 25.39864355 20.22882471 23.20031885
 21.10673535 30.62889588 22.50940423 33.82578901]
[28.10694702 26.59456152 27.6244834  26.77952051 24.96087988 22.8479707
 20.67220215 27.16646484 23.12790918 25.39864355 20.22882471 23.20031885
 21.10673535 30.62889588 22.50940423 33.82578901]
3.900193793706385 0.66185747175036 77.15153071034165
val isze = 0
idinces = [ 5  3 14  7  6  8 10  2 11 12 15  1  0  4 13  9]
training loss = 5.4152750968933105 500
training loss = 4.196526050567627 1000
training loss = 2.46589732170105 1500
training loss = 1.8207050561904907 2000
training loss = 1.4524619579315186 2500
training loss = 1.2030681371688843 3000
training loss = 1.0756057500839233 3500
training loss = 1.0276618003845215 4000
training loss = 1.014615774154663 4500
training loss = 1.011812686920166 5000
training loss = 1.0110466480255127 5500
training loss = 1.0105271339416504 6000
training loss = 1.0099376440048218 6500
training loss = 1.0091967582702637 7000
training loss = 1.008255124092102 7500
training loss = 1.0070592164993286 8000
training loss = 1.0055458545684814 8500
training loss = 1.0036389827728271 9000
training loss = 1.0012454986572266 9500
training loss = 0.9982583522796631 10000
reduced chi^2 level 2 = 0.9982519149780273
Constrained alpha: 3.5561914443969727
Constrained beta: 0.9806808829307556
Constrained gamma: 69.4231948852539
(1, 16)
(1, 0)
