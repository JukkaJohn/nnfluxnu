data before
[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 1.80517835e+01 2.07632676e+01 2.30329748e+01 2.51617763e+01
 2.68727937e+01 2.73842364e+01 2.71430290e+01 2.57755067e+01
 2.31704766e+01 1.97758501e+01 1.56585616e+01 1.13483475e+01
 7.49556649e+00 4.31283055e+00 2.04278166e+00 7.12621147e-01
 1.76482867e-01 3.78573093e-02 6.18315992e-05 0.00000000e+00
 0.00000000e+00]
7
data after
[38.81505105834603, 23.03297475747764, 25.16177631636441, 26.872793663014768, 27.38423643448949, 27.14302900591314, 25.775506665709017, 23.17047660264835, 35.43441172671609, 26.126549325949988]
8
data,sig_tot
[38.81505106 23.03297476 25.16177632 26.87279366 27.38423643 27.14302901
 25.77550667 23.1704766  35.43441173 26.12654933 24.0011234  20.59460912
 24.0471772 ]
[38.81505106 23.03297476 25.16177632 26.87279366 27.38423643 27.14302901
 25.77550667 23.1704766  35.43441173 26.12654933 24.0011234  20.59460912
 24.0471772 ]
3.8061129051282867 12.869302743705015 42.67687198997492
val isze = 0
idinces = [ 3  7 11  6  8  2 12  5 10  1  0  4  9]
training loss = 10.834630012512207 500
training loss = 9.03320598602295 1000
training loss = 5.315922737121582 1500
training loss = 2.0590713024139404 2000
(1, 13)
(1, 0)
