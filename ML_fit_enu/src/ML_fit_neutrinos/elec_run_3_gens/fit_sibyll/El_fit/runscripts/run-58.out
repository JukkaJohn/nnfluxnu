data before
[  0.           0.           0.           0.           0.
   0.           0.           0.           0.           0.
   0.           0.           0.           0.           0.
   0.           0.           0.           0.           0.
 128.70353686 148.78283719 168.15354617 187.22370306 202.75516579
 214.93512338 219.19366606 217.96930231 205.64917786 184.28630033
 155.71763212 123.41973493  90.76418067  62.18380302  39.84537931
  25.29659514  19.9822009   18.03774272   1.74792816   0.
   0.        ]
3
data after
[128.70353685897828, 148.78283719064714, 168.15354617245674, 187.2237030576873, 202.75516579301834, 214.93512337660792, 219.19366606149674, 217.96930231076, 205.64917785764695, 184.2863003275919, 155.71763212081194, 123.41973492524028, 90.76418066874594, 62.183803022389114, 39.845379313286394, 25.296595141325145, 39.76787178337821]
8
data,sig_tot
[128.70353686 148.78283719 168.15354617 187.22370306 202.75516579
 214.93512338 219.19366606 217.96930231 205.64917786 184.28630033
 155.71763212 123.41973493  90.76418067  62.18380302  39.84537931
  25.29659514  39.76787178  41.12103908  26.48390527  30.94695871
  34.91469695  37.99947578  39.94603801  40.14426542  37.5465598
  32.90800041  26.5003386   43.19923573]
[128.70353686 148.78283719 168.15354617 187.22370306 202.75516579
 214.93512338 219.19366606 217.96930231 205.64917786 184.28630033
 155.71763212 123.41973493  90.76418067  62.18380302  39.84537931
  25.29659514  39.76787178  41.12103908  26.48390527  30.94695871
  34.91469695  37.99947578  39.94603801  40.14426542  37.5465598
  32.90800041  26.5003386   43.19923573]
2.772327833707773 2.426063215940557 39.6682215851484
val isze = 0
idinces = [ 7 21  5  2 13 19 11 12  1 22 25 14 18  3 26  6 20 10 24 27  8 23 16 17
  0 15  4  9]
training loss = 2.2194507122039795 500
training loss = 1.1501681804656982 1000
training loss = 1.1076997518539429 1500
training loss = 1.103140115737915 2000
training loss = 1.0955090522766113 2500
training loss = 1.0763534307479858 3000
training loss = 1.0511554479599 3500
training loss = 1.0360945463180542 4000
training loss = 1.0286444425582886 4500
training loss = 1.0258432626724243 5000
reduced chi^2 level 2 = 1.025839924812317
Constrained alpha: 2.592503309249878
Constrained beta: 3.28625226020813
Constrained gamma: 5.9577507972717285
(1, 28)
(1, 0)
