data before
[  0.           0.           0.           0.           0.
   0.           0.           0.           0.           0.
   0.           0.           0.           0.           0.
   0.           0.           0.           0.           0.
 128.70353686 148.78283719 168.15354617 187.22370306 202.75516579
 214.93512338 219.19366606 217.96930231 205.64917786 184.28630033
 155.71763212 123.41973493  90.76418067  62.18380302  39.84537931
  25.29659514  19.9822009   18.03774272   1.74792816   0.
   0.        ]
3
data after
[128.70353685897828, 148.78283719064714, 168.15354617245674, 187.2237030576873, 202.75516579301834, 214.93512337660792, 219.19366606149674, 217.96930231076, 205.64917785764695, 184.2863003275919, 155.71763212081194, 123.41973492524028, 90.76418066874594, 62.183803022389114, 39.845379313286394, 25.296595141325145, 39.76787178337821]
8
data,sig_tot
[128.70353686 148.78283719 168.15354617 187.22370306 202.75516579
 214.93512338 219.19366606 217.96930231 205.64917786 184.28630033
 155.71763212 123.41973493  90.76418067  62.18380302  39.84537931
  25.29659514  39.76787178  41.12103908  26.48390527  30.94695871
  34.91469695  37.99947578  39.94603801  40.14426542  37.5465598
  32.90800041  26.5003386   43.19923573]
[128.70353686 148.78283719 168.15354617 187.22370306 202.75516579
 214.93512338 219.19366606 217.96930231 205.64917786 184.28630033
 155.71763212 123.41973493  90.76418067  62.18380302  39.84537931
  25.29659514  39.76787178  41.12103908  26.48390527  30.94695871
  34.91469695  37.99947578  39.94603801  40.14426542  37.5465598
  32.90800041  26.5003386   43.19923573]
4.0906461118946105 15.054940808413043 46.35925678073356
val isze = 0
idinces = [ 7 21  5  2 13 19 11 12  1 22 25 14 18  3 26  6 20 10 24 27  8 23 16 17
  0 15  4  9]
training loss = 56.783790588378906 500
training loss = 16.02288818359375 1000
training loss = 7.745055198669434 1500
training loss = 5.529123783111572 2000
training loss = 4.65970516204834 2500
training loss = 3.6460704803466797 3000
training loss = 2.040706157684326 3500
training loss = 1.9480204582214355 4000
training loss = 1.885840892791748 4500
training loss = 1.831355333328247 5000
reduced chi^2 level 2 = 1.8312464952468872
Constrained alpha: 3.4801738262176514
Constrained beta: 5.295313835144043
Constrained gamma: 29.07103729248047
(1, 28)
(1, 0)
