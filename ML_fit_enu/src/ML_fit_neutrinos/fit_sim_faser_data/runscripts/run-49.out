LHAPDF 6.5.4 loading /data/theorie/jjohn/miniconda3/envs/nnpdf_dev/share/LHAPDF/FASERv_EPOS+POWHEG_7TeV/FASERv_EPOS+POWHEG_7TeV_0000.dat
FASERv_EPOS+POWHEG_7TeV PDF set, member #0, version 1; LHAPDF ID = 70001000
LHAPDF 6.5.4 loading /data/theorie/jjohn/miniconda3/envs/nnpdf_dev/share/LHAPDF/FASERv_EPOS+POWHEG_7TeV/FASERv_EPOS+POWHEG_7TeV_0000.dat
FASERv_EPOS+POWHEG_7TeV PDF set, member #0, version 1; LHAPDF ID = 70001000
0.952680358802997 11.709795424222689 84.45837901993633
val isze = 0
idinces = [2 5 0 3 4 1]
training loss = 3.740741491317749 100
training loss = 0.8851684927940369 200
training loss = 0.7727726697921753 300
training loss = 0.7311686277389526 400
training loss = 0.6872352361679077 500
training loss = 0.6418434381484985 600
training loss = 0.5959212779998779 700
training loss = 0.550262451171875 800
training loss = 0.5055744647979736 900
training loss = 0.4624941051006317 1000
training loss = 0.42157912254333496 1100
training loss = 0.38329392671585083 1200
training loss = 0.3479970097541809 1300
training loss = 0.3159106373786926 1400
training loss = 0.28706812858581543 1500
training loss = 0.2610790729522705 1600
training loss = 0.24089303612709045 1700
training loss = 0.21374282240867615 1800
training loss = 0.18695518374443054 1900
training loss = 0.1524403691291809 2000
training loss = 0.10575847327709198 2100
training loss = 0.012790365144610405 2200
training loss = 0.008141042664647102 2300
training loss = 0.006494914647191763 2400
training loss = 0.005899117328226566 2500
training loss = 0.01033313013613224 2600
training loss = 0.005543637089431286 2700
training loss = 0.005541413091123104 2800
rep 1 done out of 1
reduced chi^2 level 2 = 0.008202929049730301
Constrained alpha: 1.9673850536346436
Constrained beta: 8.964882850646973
Constrained gamma: 64.69861602783203
(1, 6)
(1, 0)
Thanks for using LHAPDF 6.5.4. Please make sure to cite the paper:
  Eur.Phys.J. C75 (2015) 3, 132  (http://arxiv.org/abs/1412.7420)
