LHAPDF 6.5.4 loading /data/theorie/jjohn/miniconda3/envs/nnpdf_dev/share/LHAPDF/FASERv_EPOS+POWHEG_7TeV/FASERv_EPOS+POWHEG_7TeV_0000.dat
FASERv_EPOS+POWHEG_7TeV PDF set, member #0, version 1; LHAPDF ID = 70001000
LHAPDF 6.5.4 loading /data/theorie/jjohn/miniconda3/envs/nnpdf_dev/share/LHAPDF/FASERv_EPOS+POWHEG_7TeV/FASERv_EPOS+POWHEG_7TeV_0000.dat
FASERv_EPOS+POWHEG_7TeV PDF set, member #0, version 1; LHAPDF ID = 70001000
1.2382781560606455 9.908104302635776 98.05220649187501
val isze = 0
idinces = [2 5 0 3 4 1]
training loss = 1.7459893226623535 100
training loss = 0.32166439294815063 200
training loss = 0.29786309599876404 300
training loss = 0.2893807291984558 400
training loss = 0.28027719259262085 500
training loss = 0.2708422541618347 600
training loss = 0.2613357901573181 700
training loss = 0.25197821855545044 800
training loss = 0.24295376241207123 900
training loss = 0.23441451787948608 1000
training loss = 0.22647802531719208 1100
training loss = 0.2192334234714508 1200
training loss = 0.2127375453710556 1300
training loss = 0.20701545476913452 1400
training loss = 0.20207004249095917 1500
training loss = 0.19787894189357758 1600
training loss = 0.19440194964408875 1700
training loss = 0.19157986342906952 1800
training loss = 0.18934623897075653 1900
training loss = 0.18762564659118652 2000
training loss = 0.18634212017059326 2100
training loss = 0.185418039560318 2200
training loss = 0.18478259444236755 2300
training loss = 0.1843714416027069 2400
training loss = 0.18412868678569794 2500
training loss = 0.18400469422340393 2600
training loss = 0.18396279215812683 2700
training loss = 0.18397536873817444 2800
training loss = 0.18401454389095306 2900
rep 1 done out of 1
reduced chi^2 level 2 = 0.1840449571609497
Constrained alpha: 1.9288315773010254
Constrained beta: 8.720596313476562
Constrained gamma: 74.87373352050781
(1, 6)
(1, 0)
Thanks for using LHAPDF 6.5.4. Please make sure to cite the paper:
  Eur.Phys.J. C75 (2015) 3, 132  (http://arxiv.org/abs/1412.7420)
