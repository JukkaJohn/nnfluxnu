LHAPDF 6.5.4 loading /data/theorie/jjohn/miniconda3/envs/nnpdf_dev/share/LHAPDF/FASERv_EPOS+POWHEG_7TeV/FASERv_EPOS+POWHEG_7TeV_0000.dat
FASERv_EPOS+POWHEG_7TeV PDF set, member #0, version 1; LHAPDF ID = 70001000
LHAPDF 6.5.4 loading /data/theorie/jjohn/miniconda3/envs/nnpdf_dev/share/LHAPDF/FASERv_EPOS+POWHEG_7TeV/FASERv_EPOS+POWHEG_7TeV_0000.dat
FASERv_EPOS+POWHEG_7TeV PDF set, member #0, version 1; LHAPDF ID = 70001000
0.5459379981080759 1.4786025451589468 31.253908888893488
val isze = 0
idinces = [2 5 0 3 4 1]
training loss = 46.59513473510742 100
training loss = 0.5465401411056519 200
training loss = 0.32559844851493835 300
training loss = 0.2876074016094208 400
training loss = 0.24844083189964294 500
training loss = 0.19693319499492645 600
training loss = 0.23865962028503418 700
training loss = 0.167234405875206 800
training loss = 0.15197566151618958 900
training loss = 0.13111937046051025 1000
training loss = 0.10668428242206573 1100
training loss = 0.08049467206001282 1200
training loss = 0.133535236120224 1300
training loss = 0.025738587602972984 1400
training loss = 0.022499389946460724 1500
training loss = 0.007808805909007788 1600
training loss = 0.018431980162858963 1700
training loss = 0.005841502454131842 1800
training loss = 0.03582914546132088 1900
training loss = 0.003597994800657034 2000
training loss = 0.0010321324225515127 2100
training loss = 0.0004948278074152768 2200
training loss = 0.00021074815595056862 2300
training loss = 0.03690925985574722 2400
training loss = 0.00017211405793204904 2500
training loss = 0.0009247667039744556 2600
training loss = 0.00019495212472975254 2700
rep 1 done out of 1
reduced chi^2 level 2 = 0.00019495212472975254
Constrained alpha: 2.423043727874756
Constrained beta: 2.7994086742401123
Constrained gamma: 24.772502899169922
(1, 6)
(1, 0)
Thanks for using LHAPDF 6.5.4. Please make sure to cite the paper:
  Eur.Phys.J. C75 (2015) 3, 132  (http://arxiv.org/abs/1412.7420)
