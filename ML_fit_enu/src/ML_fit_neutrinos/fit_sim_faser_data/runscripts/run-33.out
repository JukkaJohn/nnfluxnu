LHAPDF 6.5.4 loading /data/theorie/jjohn/miniconda3/envs/nnpdf_dev/share/LHAPDF/FASERv_EPOS+POWHEG_7TeV/FASERv_EPOS+POWHEG_7TeV_0000.dat
FASERv_EPOS+POWHEG_7TeV PDF set, member #0, version 1; LHAPDF ID = 70001000
LHAPDF 6.5.4 loading /data/theorie/jjohn/miniconda3/envs/nnpdf_dev/share/LHAPDF/FASERv_EPOS+POWHEG_7TeV/FASERv_EPOS+POWHEG_7TeV_0000.dat
FASERv_EPOS+POWHEG_7TeV PDF set, member #0, version 1; LHAPDF ID = 70001000
0.976302966726898 16.893333296950114 47.77886281440801
val isze = 0
idinces = [2 5 0 3 4 1]
training loss = 2.067955493927002 100
training loss = 1.9654697179794312 200
training loss = 1.8480476140975952 300
training loss = 1.7128660678863525 400
training loss = 1.5640004873275757 500
training loss = 1.4037350416183472 600
training loss = 1.2319462299346924 700
training loss = 1.0450572967529297 800
training loss = 0.8382059931755066 900
training loss = 0.618666410446167 1000
training loss = 0.40768784284591675 1100
training loss = 0.2502065896987915 1200
training loss = 0.17719875276088715 1300
training loss = 0.15793117880821228 1400
training loss = 0.1478613018989563 1500
training loss = 0.14181245863437653 1600
training loss = 0.13429531455039978 1700
training loss = 0.14218226075172424 1800
training loss = 0.11993487179279327 1900
training loss = 0.12870550155639648 2000
training loss = 0.0836849957704544 2100
training loss = 0.034554291516542435 2200
training loss = 0.004218783229589462 2300
training loss = 0.003933842293918133 2400
training loss = 9.039130964083597e-05 2500
training loss = 0.0003385188465472311 2600
training loss = 8.666078792884946e-05 2700
training loss = 0.00029552908381447196 2800
rep 1 done out of 1
reduced chi^2 level 2 = 8.796196198090911e-05
Constrained alpha: 1.8234971761703491
Constrained beta: 13.545502662658691
Constrained gamma: 38.72645950317383
(1, 6)
(1, 0)
Thanks for using LHAPDF 6.5.4. Please make sure to cite the paper:
  Eur.Phys.J. C75 (2015) 3, 132  (http://arxiv.org/abs/1412.7420)
