data before
[  0.           0.           0.           0.           0.
   0.           0.           0.           0.           0.
   0.           0.           0.           0.           0.
   0.           0.           0.           0.           0.
 128.70353686 148.78283719 168.15354617 187.22370306 202.75516579
 214.93512338 219.19366606 217.96930231 205.64917786 184.28630033
 155.71763212 123.41973493  90.76418067  62.18380302  39.84537931
  25.29659514  19.9822009   18.03774272   1.74792816   0.
   0.        ]
3
data after
[128.70353685897828, 148.78283719064714, 168.15354617245674, 187.2237030576873, 202.75516579301834, 214.93512337660792, 219.19366606149674, 217.96930231076, 205.64917785764695, 184.2863003275919, 155.71763212081194, 123.41973492524028, 90.76418066874594, 62.183803022389114, 39.845379313286394, 25.296595141325145, 39.76787178337821]
8
data,sig_tot
[128.70353686 148.78283719 168.15354617 187.22370306 202.75516579
 214.93512338 219.19366606 217.96930231 205.64917786 184.28630033
 155.71763212 123.41973493  90.76418067  62.18380302  39.84537931
  25.29659514  39.76787178  41.12103908  26.48390527  30.94695871
  34.91469695  37.99947578  39.94603801  40.14426542  37.5465598
  32.90800041  26.5003386   43.19923573]
[128.70353686 148.78283719 168.15354617 187.22370306 202.75516579
 214.93512338 219.19366606 217.96930231 205.64917786 184.28630033
 155.71763212 123.41973493  90.76418067  62.18380302  39.84537931
  25.29659514  39.76787178  41.12103908  26.48390527  30.94695871
  34.91469695  37.99947578  39.94603801  40.14426542  37.5465598
  32.90800041  26.5003386   43.19923573]
3.340801343131478 9.16597808644042 16.536553710479375
val isze = 0
idinces = [ 7 21  5  2 13 19 11 12  1 22 25 14 18  3 26  6 20 10 24 27  8 23 16 17
  0 15  4  9]
training loss = 3.695948600769043 500
training loss = 2.078808546066284 1000
training loss = 2.042245626449585 1500
training loss = 2.014235734939575 2000
training loss = 1.9432518482208252 2500
training loss = 1.8827009201049805 3000
training loss = 1.8352396488189697 3500
training loss = 1.8082215785980225 4000
training loss = 1.7975633144378662 4500
training loss = 1.7893483638763428 5000
reduced chi^2 level 2 = 1.789313554763794
Constrained alpha: 2.3840885162353516
Constrained beta: 2.959130048751831
Constrained gamma: 4.815546989440918
(1, 28)
(1, 0)
