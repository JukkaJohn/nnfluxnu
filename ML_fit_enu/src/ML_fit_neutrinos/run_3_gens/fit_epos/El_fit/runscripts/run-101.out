data before
[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 1.49062519e+02 1.67988628e+02 1.84756801e+02 1.99295740e+02
 2.08864602e+02 2.10892075e+02 2.05316543e+02 1.91526206e+02
 1.70422482e+02 1.43531808e+02 1.12766530e+02 8.29920548e+01
 5.87078476e+01 3.59768908e+01 1.80225255e+01 6.48677791e+00
 1.53443149e+00 1.42783723e-01 0.00000000e+00 0.00000000e+00
 0.00000000e+00]
5
data after
[149.06251885022414, 167.98862759559862, 184.75680104024315, 199.29574034196307, 208.86460212845705, 210.89207494948326, 205.3165431855517, 191.52620601430385, 170.42248197293986, 143.53180819428323, 112.76653015785716, 82.992054832881, 58.70784764996863, 35.97689084691096, 26.18651865839047]
8
data,sig_tot
[149.06251885 167.9886276  184.75680104 199.29574034 208.86460213
 210.89207495 205.31654319 191.52620601 170.42248197 143.53180819
 112.76653016  82.99205483  58.70784765  35.97689085  26.18651866
  25.01956498  29.76566371  34.57853534  39.0537924   42.78745488
  45.03327904  45.07523072  43.28156672  39.17596164  33.34568609
  25.6385597   45.33953963]
[149.06251885 167.9886276  184.75680104 199.29574034 208.86460213
 210.89207495 205.31654319 191.52620601 170.42248197 143.53180819
 112.76653016  82.99205483  58.70784765  35.97689085  26.18651866
  25.01956498  29.76566371  34.57853534  39.0537924   42.78745488
  45.03327904  45.07523072  43.28156672  39.17596164  33.34568609
  25.6385597   45.33953963]
4.429304794594257 10.844721012900884 71.11743805295023
val isze = 0
idinces = [ 7  5 18 21 11  1  2 12 24 14 13 20  3 25  6 19 10 23 26  8 22 16 17  0
 15  4  9]
training loss = 43.8683967590332 500
training loss = 42.797401428222656 1000
training loss = 40.43163299560547 1500
training loss = 19.922739028930664 2000
training loss = 11.703317642211914 2500
training loss = 8.576990127563477 3000
training loss = 6.766768932342529 3500
training loss = 5.762635231018066 4000
training loss = 5.137767791748047 4500
training loss = 4.664693355560303 5000
(1, 27)
(1, 0)
